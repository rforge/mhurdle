\documentclass[nojss]{jss}
\usepackage{rotating}
\usepackage{amsmath}
\usepackage{wasysym}

\usepackage{amssymb, amsfonts}


%\VignetteIndexEntry{Multiple Hurdle Models in R: the mhurdle Package}
%\VignetteDepends{Formula, truncreg, maxLik}
%\VignetteKeywords{Limited dependent variable, tobit, hurdle models, econometric computing, R}
%\VignettePackage{mhurdle}

\title{Multiple Hurdle Models in \proglang{R}: The \pkg{mhurdle} Package}

\Plaintitle{Multiple Hurdle Models in R: The mhurdle Package}

% \footnote{This package has been developed as part
% of a PhD dissertation carried out by St\'ephane Hoareau
% \cite{Hoareau/09} at the University of La R\'eunion under the
% supervision of Fabrizio Carlevaro and Yves Croissant.}


\author{Fabrizio Carlevaro\\Universit\'e de Gen\`eve \And
 Yves Croissant\\Universit\'e de la R\'eunion \And
 St\'ephane Hoareau\\Universit\'e de la R\'eunion}

\Plainauthor{Fabrizio Carlevaro, Yves Croissant, St\'ephane Hoareau}

\Address{
Fabrizio Carlevaro\\
Facult\'e des sciences \'economiques et sociales\\
Universit\'e de Gen\`eve\\
Uni Mail\\
40 Bd du Pont d'Arve\\
CH-1211 Gen\`eve 4\\
Telephone: +41/22/3798914\\
E-mail:\email{fabrizio.carlevaro@unige.ch}
\\
\\
Yves Croissant\\
Facult\'e de Droit et d'Economie\\
Universit\'e de la R\'eunion\\
15, avenue Ren\'e Cassin\\
BP 7151\\
F-97715 Saint-Denis Messag Cedex 9\\
Telephone: +33/262/938446\\
E-mail: \email{yves.croissant@univ-reunion.fr}
\\
\\
St\'ephane Hoareau\\
Facult\'e de Droit et d'Economie\\
Universit\'e de la R\'eunion\\
15, avenue Ren\'e Cassin\\
BP 7151\\
F-97715 Saint-Denis Messag Cedex 9\\
Telephone: +33/262/938446\\
E-mail: \email{stephane.hoareau@univ-reunion.fr}
}

%% need no \usepackage{Sweave.sty}

\Abstract{ \pkg{mhurdle} is a package for \proglang{R} enabling the
  estimation of a wide set of regression models where the dependent
  variable is left censored at zero, which is typically the case in
  household expenditure surveys.  These models are of particular
  interest to explain the presence of a large proportion of zero
  observations for the dependent variable by means of up to three
  censoring mechanisms, called hurdles. For the analysis of censored
  household expenditure data, these hurdles express a good
  selection mechanism, a desired consumption mechanism and a purchasing
  mechanism, respectively. \pkg{mhurdle} models are specified in a
  fully parametric form and estimated using the maximum likelihood
  method for random samples. Model evaluation and selection are tackled
  by means of goodness of fit measures and Vuong tests. Software rationale
  and user's guidelines are presented and illustrated with actual examples.}

\Keywords{households' expenditure survey analysis, censored regression models,
hurdle models, maximum likelihood estimation, nonlinear goodness of fit measures,
Vuong tests for model selection, \proglang{R}}

\Plainkeywords{households' expenditure survey analysis, censored regression models,
hurdle models, maximum likelihood estimation, nonlinear goodness of fit measures,
Vuong tests for model selection, R}

\begin{document}


\maketitle




\section{Introduction}
<<echo=FALSE,results=hide>>=
options(prompt= "R> ", useFancyQuotes = FALSE)
@
Data collected by means of households' expenditure survey may present
a large proportion of zero expenditures due to many households
recording, for one reason or another, no expenditure for some
items. Analyzing these data requires to model any expenditure with a
large proportion of nil observations as a dependent variable left
censored at zero.

Since the seminal paper of \citet{TOBIN/58}, a large econometric
literature has been developed to deal correctly with this problem of
zero observations. The problem of censored data has been treated for a
long time in the statistics literature dealing with survival models
which are implemented in \proglang{R} with the \pkg{survival} package
of \citet{SURVA/08}. It has also close links with the problem of
selection bias, for which some methods are implemented in the
\pkg{sampleSelection} package of \citet{TOOME/HENNI/08}. It is also
worth mentioning that a convenient interface to \code{survreg}, called
\code{tobit}, particularly aimed at econometric applications is
available in the AER package of \citet{KLEI/ZEIL/08}.

In applied microeconometrics, different decision mechanisms have been
put forward to explain the appearance of zero expenditure
observations. The original Tobin's model takes only one of these
mechanisms into account. With \pkg{mhurdle}, up to three mechanisms
generating zero expenditure observations may be introduced in the
model\footnote{This package has been developed as part of a PhD
  dissertation carried out by St\'ephane \citet{HOAR/09} at the
  University of La R\'eunion under the supervision of Fabrizio
  Carlevaro and Yves Croissant.}. More specifically, we consider the
following three zero expenditure generating mechanisms.

\begin{description}
\item[A good selection mechanism (hurdle 1)]. According to this
  mechanism, the consumer first decides which goods to include in its
  choice set and, as a consequence, he can discard some marketed goods
  because he dislikes them (like meat for vegetarians or wine for
  non-drinkers) or considers them harmful (like alcohol, cigarettes,
  inorganic food, holidays in dangerous countries), among
  others.\\
  This censoring mechanism has been introduced in empirical demand
  analysis by \citet{CRAGG/71}. It allows to account for the
  non-consumption of a good as a consequence of a fundamentally
  non-economic decision motivated by ethical, psychological or social
  considerations altering the consumer's preferences.

\item[A desired consumption mechanism (hurdle 2)]. According to this
  mechanism, once a good has been selected, the consumer decides which
  amount to consume and, as a consequence of his preferences, resources
  and selected good prices, its rational decision can turn out to be a
  negative desired consumption level leading to a nil consumption.\\
  The use of this mechanism to explain the presence of zero
  observations in family expenditure surveys introduced by
  \citet{TOBIN/58}. Its theoretical relevance has been later
  rationalised by the existence of corner solutions to the
  microeconomic problem of rational choice of the neoclassical
  consumer. See section 10.2 of \citet{AMEM/85}, for an elementary
  presentation of this issue, and chapter 4 of \citet{PUDNEY/89}, for
  a more comprehensive one.

\item[A purchasing mechanism (hurdle 3)]. According to this mechanism,
  once a consumption decision has been taken, the consumer sets up the
  schedule at which to buy the good and, as a consequence of its
  purchasing strategy, zero expenditure may be observed if the survey
  by which these data are collected is carried out over a too short
  period with respect to the frequency at which the good is bought.\\
  This censoring mechanism has been introduced in empirical demand
  analysis by \citet{DEATO/IRISH/84}. It allows to account for the
  non-purchase of a good not because the good is not consumed but
  because it is a durable or a storable good infrequently bought. By
  the same token, this mechanism allows to derive from observed
  expenditures, the rate of use of a durable good or the rate of
  consumption of a stored non durable good.
\end{description}

For each of these censoring mechanisms, a continuous latent variable
is defined, indicating that censoring is in effect when the latent
variable is negative. These latent variables are modelled as the sum of
a linear combination of explanatory variables and of a normal random
disturbance with a possible correlation between the disturbances of
different latent variables.  By combining part or the whole set of
these censoring mechanisms, we generate a set of non-nested parametric
models that can be used to explain censored expenditure data depending
on the structural censoring mechanisms that a priori information
suggests to be at work.

It is worth mentioning that, although this formal model has been
primarily developed to deal with censored household expenditure data,
its practical scope is not restricted to empirical demand analysis. A
quite natural other area of application is represented by the
empirical analysis of labour supply. In this context, hurdle 1 can
indeed be reinterpreted as a non-economic mechanism of labour market
participation; hurdle 2 as a desired working hours mechanism based on
the neoclassical model of labour supply that can generate negative
desired working hours leading to a nil labour supply; hurdle 3 as an
unemployment mechanism explaining zero hours worked as a result of
spells of unemployment. Note also that even within the realm of demand
analysis, the economic interpretation of hurdles 1, 2 and 3 may
require to be adapted to the specific features of available data, as
we illustrate by an empirical application presented at the end of the
paper (see section~\ref{sec:examples}).

Our hurdle models are specified as fully parametric models allowing
estimation and inference within an efficient maximum likelihood
framework. In order to identify a relevant model specification,
goodness of fit measures for model evaluation and selection, as well
as Vuong tests for discriminating between nested, strictly non nested
and overlapping models have been implemented in \pkg{mhurdle}
package. Vuong tests remarkably permit to compare two competing models
when both, only one, or neither of them contain the true mechanism
generating the sample of observations.  More precisely, such tests
allow to assess which of the two competing models is closest to the
true unknown model according to the Kullback-Leibler information
criterion. Therefore, such symmetric tests are not intended, as
classical Neyman-Pearson tests, to pinpoint the chimeric true model,
but to identify a best parametric model specification (with respect to
available observations) among a set of competing specifications. As a
consequence, they can provide inconclusive results, which prevent from
disentangling some competing models, and when they are conclusive,
they don't guarantee an identification of the relevant model
specification.

The paper is organised as follows: Section~\ref{sec:limdepvar}
presents the rationale of our modelling strategy.
Section~\ref{sec:estevalsel} presents the theoretical framework for
model estimation, evaluation and selection. Section~\ref{sec:software}
discusses the software rationale used in the
package. Section~\ref{sec:examples} illustrates the use of
\pkg{mhurdle} with several examples. Section~\ref{sec:conclusion}
concludes.

\section{Modelling strategy}
\label{sec:limdepvar}

\subsection{Model specification}
\label{sec:modelspec}

Our modelling strategy is intended to model the level $y$ of expenditures
of a household for a given good or service during a given period of observation.
To this purpose, we use up to three zero expenditure generating mechanisms,
called hurdles, and a demand function.

Each hurdle is represented by a probit model resting on one of the following three
latent dependent variables relations:

\begin{equation}\label{eq1}
\left\{
\begin{array}{l}
  y_1^* = \beta_1^\top x_1 + \epsilon_1 \\[4pt]
  y_2^* = \beta_2^\top x_2 + \epsilon_2 \\[4pt]
  y_3^* = \beta_3^\top x_3 + \epsilon_3 \\
\end{array}
\right.
\end{equation}

where $x_1$, $x_2$, $x_3$ stand for column-vectors of explanatory
variables (called covariates in the followings), $\beta_1$, $\beta_2$,
$\beta_3$ for column-vectors of the impact coefficients of the
explanatory variables on the continuous latent dependent variables $y_1^*$, $y_2^*$,
$y_3^*$ and $\epsilon_1$, $\epsilon_2$, $\epsilon_3$ for normal random
disturbances.

\begin{itemize}

\item Hurdle 1 models the household decision of selecting or not
  selecting the good we consider as a relevant consumption good,
  complying with household's ethical, psychological and social
  convictions and habits. This good selection mechanism explains the
  outcome of a binary choice that can be coded by a binary variable
  $I_1$ taking value 1 if the household decides to enter the good in
  its basket of relevant consumption goods and 0 otherwise. The
  outcome of this binary choice is modelled by associating the decision
  to select the good to positive values of the latent variable $y_1^*$
  and that to reject the good to negative values of $y_1^*$.
  Therefore, good selection or rejection is modelled as a probability
  choice where selection occurs with probability $P(I_1=1)=P(y_1^*>0)$
  and rejection
  with probability $P(I_1=0)=P(y_1^*\leq 0)=1-P(y_1^*>0)$.\\
  Note that if this mechanism is inoperative, this probit model must
  be replaced by a singular probability choice model where
  $P(I_1=1)=1$ and $P(I_1=0)=0$.

\item Hurdle 2 models the household decision of consuming or not
  consuming the selected good, given its actual economic
  conditions. This desired consumption mechanism explains the outcome
  of a binary choice coded by a binary variable $I_2$ taking value 1
  if the household decides to consume the good and 0 otherwise.  The
  outcome of this binary choice is modelled by associating the decision
  to consume the selected good to a positive value of its desired
  consumption level, represented by the latent variable $y_2^*$, and
  that of not to consume the good to negative values of
  $y_2^*$. Therefore, when this zero expenditure generating mechanism
  is operative, it also models the level of desired consumption
  expenditures by means of a Tobit model identifying the desired
  consumption expenditures to the value of latent variable $y_2^*$,
  when it is positive, and to zero, when it is negative.\\
  Conversely, when the desired consumption mechanism is inoperative,
  implying that the desired consumption cannot be a corner solution of
  a budget constrained problem of utility minimisation, we must
  replace not only the probit model explaining the variable $I_2$ by a
  singular probability choice model where $P(I_2=1)=1$, but also the
  Tobit demand function by a demand model enforcing non-negative
  values on the latent variable $y_2^*$. For the time being, two
  functional forms of this demand model have been programmed in
  \pkg{mhurdle}, namely a log-normal functional form :

  \begin{equation}\label{eq2}
  \ln y_2^* = \beta_2^\top x_2+\epsilon_2
  \end{equation}

  and a truncated Tobit model, defined by the second of the set of
  linear relationships~(\ref{eq1}) with $\epsilon_2$ distributed as a
  normal random disturbance left-truncated at $\epsilon_2 =
  -\beta_2^\top x_2$, as suggested by \citet{CRAGG/71}. Nevertheless,
  to avoid a cumbersome analytic presentation of our models, in the
  following we only consider the log-normal model specification.

\item Hurdle 3 models the household decision to purchase or not to
  purchase the good during the survey period over which expenditure
  data are collected. This purchasing mechanism also explains the
  outcome of a binary choice, coded by a binary variable $I_3$ taking
  value 1 if the household decides to buy the good during the period
  of statistical observation and 0 otherwise.  The probit model we use
  associates the purchasing decision to positive values of latent
  variable $y_3^*$ and that of not purchasing to negative
  values of $y_3^*$.\\
  By assuming that consumption and purchases are uniformly distributed
  over time, but according to different timetables entailing a
  frequency of consumption higher than that of purchasing, we can also
  interpret the probability $P(I_3=1)=P(y_3^*>0)$ as measuring the
  share of expenditures to consumption during the observation
  period. This allows to relate the observed level of expenditures $y$
  to the unobserved level of consumption $y_2^*$ during the
  observation period, using the following identity:

  \begin{equation}\label{eq3}
  y = \frac{y_2^*}{P(I_3=1)} I_1 I_2 I_3 .
  \end{equation}

  When the purchasing mechanism is inoperative, the previous probit
  model must be replaced by a singular probability choice model where
  $P(I_3=1)=1$.  In such a case, the observed level of expenditures is
  identified to the level of consumption, implying $y=y_2^* I_1 I_2$.

\end{itemize}

A priori information may suggest that one or more of these censoring
mechanisms are not in effect. For instance, we know in advance that
all households purchase food regularly, implying that the first two
censoring mechanisms are inoperative for food.  In this case, the
relevant model is defined by only two relations: one defining the
desired consumption level of food, according to a log-normal
specification or a truncated Tobit model, and the other the decision
to purchase food during the observation period.

Figure~\ref{fig:arbre2} outlines the full set of special models that
can be generated by selecting which of these three mechanisms are in
effect and which are not.  It shows that 8 different models can be
dealt with by means of the \pkg{mhurdle} package.

\begin{sidewaysfigure}
\caption{\label{fig:arbre2} The full set of mhurdle special models.}
  \includegraphics[width=20cm,height=17cm]{typo1.pdf}
\end{sidewaysfigure}

Among these models, one is not concerned by censored data, namely
model 1.  This model is relevant only for modelling uncensored
samples. All the other models are potentially able to analyse censored
samples by combining up to the three censoring mechanisms described
above. With the notable exception of the standard Tobit model 3, that
can be estimated also by the \pkg{survival} package of
\citet{SURVA/08} or the AER package of \citet{KLEI/ZEIL/08}, these
models cannot be found in an other \proglang{R} package.

Some of \pkg{mhurdle} models have already been used in applied
econometric literature. In particular, model 2 is a single-hurdle good
selection model originated by \citet{CRAGG/71}. The double-hurdle
model combining independent good selection (hurdle 1) and desired
consumption (hurdle 2) censoring mechanisms is also due to
\citet{CRAGG/71}. An extension of this double-hurdle model to
dependent censoring mechanisms has been originated by
\citet{BLUNDELL/87}.

P-Tobit model 7 is due to \citet{DEATO/IRISH/84} and explains zero
purchases by combining the desired consumption censoring mechanism
(hurdle 2) with the purchasing censoring mechanism (hurdle 3).
Model 4 is a single-hurdle model not yet used in applied demand analysis,
where the censoring mechanism in effect is that of infrequent purchases
(hurdle 3).

Among the original models encompassed by \pkg{mhurdle}, models 6 is a
double-hurdle model combining good selection (hurdle 1) and purchasing
(hurdle 3) mechanisms to explain censored samples. Model 8 is an
original triple-hurdle model originated in \citet{HOAR/09}.
This model explains censored purchases either as the result of good
rejection (hurdle 1), negative desired consumption (hurdle 2) or
infrequent purchases (hurdle 3).

To derive the form of the probability distribution of the observable
dependent variable $y$, we must specify the joint distribution of the
random disturbances entering the structural relations of these models.

\begin{itemize}

\item Models 8 and 6 are trivariate hurdle models as they involve
  disturbances $\epsilon_1$, $\epsilon_2$ and $\epsilon_3$,
  distributed according to the trivariate normal density function:

  \begin{equation}\label{eq4}
    \frac{1}{\sigma}\phi\left(\epsilon_1,\frac{\epsilon_2}{\sigma},\epsilon_3;
      \rho_{12},\rho_{13},\rho_{23}\right),
  \end{equation}

  where

  $$
  \phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})={\displaystyle
    \frac{\exp\left\{-\frac{\rho^{11}z_1^2+\rho^{22}z_2^2+\rho^{33}z_3^2
          -2[\rho^{12}z_1z_2+\rho^{13}z_1z_3+\rho^{23}z_2z_3]}{2}\right\}}
    {\sqrt{(2\pi)^3}\mid R\mid}},
  $$
  with
  $$
  |R|=1-\rho_{12}^2-\rho_{13}^2-\rho_{23}^2+2\rho_{12}\rho_{13}\rho_{23},
  $$
  $$
  \rho^{11}=\frac{1-\rho_{23}^2}{\mid R\mid},\quad
  \rho^{22}=\frac{1-\rho_{13}^2}{\mid R\mid},\quad
  \rho^{33}=\frac{1-\rho_{12}^2}{\mid R\mid},
  $$
  $$
  \rho^{12}=\frac{\rho_{12}-\rho_{13}\rho_{23}}{\mid R\mid},\quad
  \rho^{13}=\frac{\rho_{13}-\rho_{12}\rho_{23}}{\mid R\mid},\quad
  \rho^{23}=\frac{(\rho_{23}-\rho_{12}\rho_{13})}{\mid R\mid},
  $$

  denotes the density
  function of a standard trivariate normal distribution and $\rho_{12}$, $\rho_{13}$,
  $\rho_{23}$ the correlation coefficients between the couples of normal standard
  random variables $z_1$ and $z_2$, $z_1$ and $z_3$, $z_2$ and $z_3$, respectively.
  As the unit of measurement of $\epsilon_1$ and $\epsilon_3$ are not identified,
  these disturbances are normalised by setting their variances equal to 1.

\item Models 7 and 4 are bivariate hurdle models as they involve disturbances
  $\epsilon_2$ and $\epsilon_3$, distributed according to the bivariate normal
  density function:

  \begin{equation}\label{eq5}
  \frac{1}{\sigma}\phi\left(\frac{\epsilon_2}{\sigma},\epsilon_3;\rho_{23}\right),
  \end{equation}

  where

  $$
  \phi(z_1,z_2;\rho)=\frac{\exp\left\{-\frac{z_1^2+z_2^2-2\rho z_1z_2}{2(1-\rho^2)}\right\}}
  {2\pi\sqrt{1-\rho^2}}
  $$

  denotes the density function of a standard bivariate normal distribution with
  correlation coefficient $\rho$.

\item Models 5 and 2 are also bivariate hurdle models but they involve disturbances
  $\epsilon_1$ and $\epsilon_2$ which density function is therefore written as:

  \begin{equation}\label{eq6}
  \frac{1}{\sigma}\phi\left(\epsilon_1,\frac{\epsilon_2}{\sigma};\rho_{12}\right).
  \end{equation}

\item Finally, models 3 and 1 are univariate hurdle models involving only
  disturbance $\epsilon_2$, which density function writes therefore:

  \begin{equation}\label{eq7}
  \frac{1}{\sigma}\phi\left(\frac{\epsilon_2}{\sigma}\right),
  \end{equation}

  where

  $$
  \phi(z_1)=\frac{\exp\left\{-\frac{z_1^2}{2}\right\}}{\sqrt{2\pi}}
  $$

  denotes the density function of a standard univariate normal
  distribution.

\end{itemize}

A priori information may also suggest to set to zero some or all
correlations between the random disturbances entering these models,
entailing a partial or total independence between the above defined
censoring mechanisms. The use of this a priori information generates,
for each trivariate or bivariate hurdle model of Figure 1, a subset of
special models all nested within the general model from which they are
derived. For a trivariate hurdle model the number of special models so
derived is equal to 7, but for a bivariate hurdle model only one
special model is generated, namely the model obtained by assuming the
independence between the two random disturbances of the model.

In the following, we shall work out the distribution of our hurdle
models in their general case, but considering the difficulties of
implementing trivariate hurdle models in their full generality, for
these models only the special cases of independence or dependence
between one of hurdles 1 or 3 and the desired consumption equation,
which seems the most relevant for empirical applications, have been
programmed in \pkg{mhurdle}. The extension of our package to more
general model specifications is in progress.

\subsection{Likelihood function}

As for the standard Tobit model, the probability distribution of the
observed censored variable $y$ of our hurdle models is a
discrete-continuous mixture, which assigns a probability mass $P(y=0)$
to $y=0$ and a density function $f_+(y)$ to any $y>0$, with:

\begin{equation}\label{eq8}
P(y=0)+\int_0^\infty f_+(y)dy=1.
\end{equation}

The probability mass $P(y=0)=1-P(y>0)$ may be computed by integrating
the joint density function of the latent variables entering the hurdle
model over their positive values.

\begin{itemize}

\item For trivariate hurdle model 8, using the change of variables:

  \begin{equation}\label{eq9}
  \left\{
  \begin{array}{l}
   z_1  =  y_1^* - \beta_1^\top x_1 \\[4pt]
   z_2  =  {\displaystyle\frac{y_2^* - \beta_2^\top x_2}{\sigma}} \\[8pt]
   z_3  =  y_3^* - \beta_3^\top x_3 \\
  \end{array}
  \right.
  \end{equation}

  this approach leads to:

  \begin{equation}\label{eq10}
  \begin{array}{l}
  P(y=0) ={\displaystyle 1-\int_{-\beta_1^\top x_1}^\infty \int_{-\frac{\beta_2^\top x_2}{\sigma}}^\infty
  \int_{-\beta_3^\top x_3}^\infty \phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})
  dz_1 dz_2 dz_3}\\[16pt]
  \phantom{P(y=0)} ={\displaystyle 1-\Phi(\beta_1^\top x_1,\frac{\beta_2^\top x_2}{\sigma},
  \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23})},
  \end{array}
  \end{equation}

  where $\Phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})$ denotes the distribution
  function of a standard trivariate normal distribution with correlation coefficients
  $\rho_{12}$, $\rho_{13}$ and $\rho_{23}$.

\item For trivariate hurdle model 6, using the change of variables:

  \begin{equation}\label{eq11}
  \left\{
  \begin{array}{l}
   z_1 = y_1^* - \beta_1^\top x_1 \\[4pt]
   z_2 = {\displaystyle\frac{\ln y_2^* - \beta_2^\top x_2}{\sigma}} \\[8pt]
   z_3 = y_3^* - \beta_3^\top x_3 \\
  \end{array}
  \right.
  \end{equation}

  this approach leads to:

  \begin{equation}\label{eq12}
  \begin{array}{l}
  P(y=0)={\displaystyle 1-\int_{-\beta_1^\top x_1}^{\infty} \int_{-\infty}^\infty
  \int_{-\beta_3^\top x_3}^{\infty} \phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})
  dz_1 dz_2 dz_3}\\[16pt]
  \phantom{P(y=0)}={\displaystyle 1-\Phi(\beta_1^\top x_1,\beta_3^\top x_3;\rho_{13})},
  \end{array}
  \end{equation}

  where $\Phi(z_1,z_2;\rho)$ denotes the distribution function of a standard
  bivariate normal distribution with correlation coefficient $\rho$.

\item The probability mass $P(y=0)$ for bivariate hurdle models 7 and 5 and
  univariate hurdle model 3 can be derived from that of trivariate model 8
  by eliminating hurdles 1, 3, 1 and 3, respectively.
  Likewise, this probability for bivariate hurdle models 4 and 2 can be derived
  from that of trivariate hurdle model 6 by eliminating hurdles 1 and 3, respectively.
  Corresponding formulas of $P(y=0)$ for all this special cases implemented in
  \proglang{R} are presented in Table \ref{tab:typo}, using the following notations:
  $$
  \Phi_1=\Phi(\beta_1^\top x_1),\quad \Phi_2=\Phi\left(\frac{\beta_2^\top x_2}{\sigma}\right),
  \quad \Phi_3=\Phi(\beta_3^\top x_3),
  $$
  $$
  \Phi_{12}=\left(\beta_1^\top x_1,\frac{\beta_2^\top x_2}{\sigma};\rho_{12}\right),\quad
  \Phi_{23}=\left(\frac{\beta_2^\top x_2}{\sigma},\beta_3^\top x_3;\rho_{23}\right),
  $$
  where $\Phi(z)$ denotes the distribution function of a standard
  univariate normal distribution.

\end{itemize}

\begin{sidewaystable}
  \caption{Characteristics of mhurdle special models implemented in
  \proglang{R}\label{tab:typo}}\vspace{.5cm}

  \begin{tabular}{|l|lll|lll|l|l|l|}\hline\hline
id & $h_1$ & $h_2$ & $h_3$ & $\rho_{12}$ & $\rho_{13}$ & $\rho_{23}$  & $P(y=0)$ & $f_+(y)$ & $\mbox{E}(y \mid y > 0)$\\\hline\hline
1 &$\square$&$\square$&$\square$&$\square$&$\square$&$\square$& $0$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln y - \beta_2^{\top}x_2}{\sigma}\right)$ & $\exp\left\{\beta_2^{\top}x_2 + \frac{\sigma^2}{2}\right\}$\\
2i &$\blacksquare$&$\square$&$\square$&$\square$&$\square$&$\square$& $1 - \Phi_1$& $\frac{1}{\sigma y}\phi\left(\frac{\ln y -\beta_2^{\top}x_2}{\sigma}\right)\Phi_1$& $\exp\left\{\beta_2^{\top} x_2 + \frac{\sigma^2}{2}\right\}$\\
2d &$\blacksquare$&$\square$&$\square$&$\blacksquare$&$\square$&$\square$ & $1 - \Phi_1$& $\frac{1}{\sigma y}\phi\left(\frac{\ln y -\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1+\rho_{12}\frac{\ln y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)$ & $\exp\left\{\beta_2^{\top} x_2 + \frac{\sigma^2}{2}\right\}\frac{\Phi\left(\beta_1^{\top}x_1+\sigma\rho_{12}\right)}{\Phi_1}$\\
3 &$\square$&$\blacksquare$&$\square$&$\square$&$\square$&$\square$& $1 - \Phi_2$ & $\frac{1}{\sigma}\phi\left(\frac{y-\beta_2^{\top}x_2}{\sigma}\right)$ & $\beta_2^{\top}x_2+\sigma\frac{\phi_2}{\Phi_2}$\\
4i &$\square$&$\square$&$\blacksquare$&$\square$&$\square$&$\square$& $1 - \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^{\top}x_2}{\sigma}\right)\Phi_3$ & $\exp\left\{\beta_2^{\top} x_2 + \frac{\sigma^2}{2}\right\}\frac{1}{\Phi_3}$ \\
4d &$\square$&$\square$&$\blacksquare$&$\square$&$\square$ &$\blacksquare$& $1 - \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln (\Phi_3 y)-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\ln (\Phi_3 y) - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)$  & $\exp\left\{\beta_2^{\top} x_2
+ \frac{\sigma^2}{2}\right\}\frac{\Phi\left(\beta_3^{\top}x_3+\sigma\rho_{23}\right)}{\Phi_3^2}$\\
5i &$\blacksquare$&$\blacksquare$&$\square$&$\square$&$\square$&$\square$& $1 - \Phi_1\Phi_2$ & $\frac{1}{\sigma}\phi\left(\frac{y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_1$ & $\beta_2^{\top} x_2 + \sigma\frac{\phi_2}{\Phi_{2}}$\\
5d &$\blacksquare$&$\blacksquare$&$\square$&$\blacksquare$&$\square$&$\square$&$1 - \Phi_{12}$ &
$\frac{1}{\sigma}\phi\left(\frac{y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1 + \rho_{12}\frac{y-\beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)$ & $\beta_2^{\top} x_2 + \sigma \frac{\Psi_{2|1}}{\Phi_{12}}$\\
6i &$\blacksquare$&$\square$&$\blacksquare$&$\square$&$\square$&$\square$& $1 - \Phi_1 \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln (\Phi_3 y) -\beta_2^{\top}x_2}{\sigma}\right)\Phi_1\Phi_3$ &$\exp\left\{\beta_2^{\top}x_2+\frac{\sigma^2}{2}\right\}\frac{1}{\Phi_3}$ \\
6d1 &$\blacksquare$&$\square$&$\blacksquare$&$\blacksquare$&$\square$&$\square$& $1 - \Phi_1 \Phi_3$ &  $\frac{1}{\sigma y}\phi\left(\frac{(\ln \Phi_3 y) -\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1+\rho_{12}\frac{(\ln y \Phi_3) - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)\Phi_3$&
$\exp\left\{\beta_2^{\top} x_2 + \frac{\sigma^2}{2}\right\}\frac{\Phi\left(\beta_1^{\top}x_1+\sigma\rho_{12}\right)}{\Phi_1\Phi_3}$\\
6d3 &$\blacksquare$&$\square$&$\blacksquare$&$\square$&$\square$ &$\blacksquare$& $1 - \Phi_1 \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln (\Phi_3 y)-\beta_2^{\top}x_2}{\sigma}\right)\Phi_1\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\ln (\Phi_3 y) - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)$& $\exp\left\{\beta_2^{\top} x_2
+\frac{\sigma^2}{2}\right\}\frac{\Phi\left(\beta_3^{\top}x_3+\sigma\rho_{23}\right)}{\Phi_3^2}$\\
7i &$\square$&$\blacksquare$&$\blacksquare$&$\square$&$\square$&$\square$& $1 - \Phi_2 \Phi_3$& $\frac{1}{\sigma}\phi\left(\frac{\Phi_3y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_3^2$ & $\frac{\beta_2^{\top} x_2}{\Phi_3}
+\sigma \frac{\phi_2}{\Phi_2 \Phi_3}$\\
7d &$\square$&$\blacksquare$&$\blacksquare$&$\square$&$\square$ &$\blacksquare$& $1 - \Phi_{23}$& $\frac{1}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\Phi_3 y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)\Phi_3$ & $\frac{\beta_2^{\top} x_2}{\Phi_3}
+ \sigma \frac{\Psi_{2|3}}{\Phi_{23}\Phi_3}$ \\
8i  &$\blacksquare$&$\blacksquare$&$\blacksquare$&$\square$&$\square$&$\square$& $1-\Phi_1\Phi_2\Phi_3$& $\frac{1}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_1\Phi_3^2$& $\frac{\beta_2^{\top} x_2}{\Phi_3} + \sigma \frac{\phi_2}{\Phi_2 \Phi_3}$ \\
8d1 &$\blacksquare$&$\blacksquare$&$\blacksquare$&$\blacksquare$&$\square$&$\square$&$1 - \Phi_{12}\Phi_3$& $\frac{1}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1 + \rho_{12}\frac{\Phi_3 y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)\Phi_3^2$ & $\frac{\beta_2^{\top} x_2}{\Phi_3}
+ \sigma \frac{\Psi_{2|1}}{\Phi_{12} \Phi_3}$ \\
8d3 &$\blacksquare$&$\blacksquare$&$\blacksquare$&$\square$&$\square$ &$\blacksquare$&$1 - \Phi_1\Phi_{23}$& $\frac{1}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_1\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\Phi_3 y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)\Phi_3$ & $\frac{\beta_2^{\top} x_2}{\Phi_3}
+ \sigma \frac{\Psi_{2|3}}{\Phi_{23} \Phi_3}$  \\ \hline\hline
\end{tabular}

\vspace{.5cm}

A blackened square indicates which hurdle or correlation is assumed to be at work in the model.

\end{sidewaystable}

The density function $f_+(y)$ may be computed by performing: first the
change of variables $y_2^* = P(I_3=1)y = \Phi_3y$ on the joint density
function of the latent variables entering the hurdle model; then by
integrating this transformed density function over the positive values
of latent variables $y_1^*$ and $y_3^*$.

\begin{itemize}
\item For trivariate hurdle model 8 this transformed density function
  is written as:

  \begin{equation}\label{eq13}
    \frac{\Phi_3}{\sigma}\phi\left(y_1^*-\beta_1^\top x_1,\frac{\Phi_3 y-\beta_2^\top x_2}
      {\sigma},y_3^*-\beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right).
  \end{equation}

  To perform the analytical integration of this function, it is useful
  to rewrite it as the product of the marginal distribution of $y$,
  namely:

  \begin{equation}\label{eq14}
    \frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)
  \end{equation}

  and of the joint density function of $y_1^*$ and $y_3^*$ conditioned
  with respect to $y$, which can be written as follows:

  \begin{equation}\label{eq15}
    \frac{1}{\sigma_{1|2}\sigma_{3|2}}\phi\left(\frac{y_1^*-\mu_{1|2}}{\sigma_{1|2}},
      \frac{y_3^*-\mu_{3|2}}{\sigma_{3|2}}; \rho_{13|2}\right),
  \end{equation}

  with:
  $$
  \mu_{1|2}=\beta_1^\top x_1+\rho_{12}\frac{\Phi_3y-\beta_2^\top
    x_2}{\sigma}, \quad \mu_{3|2}=\beta_3^\top
  x_3+\rho_{23}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma},
  $$
  $$
  \sigma_{1|2}^2=1-\rho_{12}^2, \quad \sigma_{3|2}^2=1-\rho_{23}^2,
  \quad
  \rho_{13|2}=\frac{\rho_{13}-\rho_{12}\rho_{23}}{\sqrt{1-\rho_{12}^2}\sqrt{1-\rho_{23}^2}}.
  $$

  Using this factorization of the density function of $y_1^*$, $y$ and
  $y_3^*$, we obtain:


  \begin{equation}\label{eq16}
  \begin{array}{l}
    f_+(y)={\displaystyle\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)}\\[12pt]
    \phantom{f_+(y)} \times {\displaystyle\int_0^\infty\int_0^\infty \frac{1}{\sigma_{1|2}\sigma_{3|2}}\phi\left(\frac{y_1^*-\mu_{1|2}}{\sigma_{1|2}},
        \frac{y_3^*-\mu_{3|2}}{\sigma_{3|2}}; \rho_{13|2}\right)dy_1^*dy_3^*} \\[16pt]
    \phantom{f_+(y)}= {\displaystyle\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)
      \int_{-\frac{\mu_{1|2}}{\sigma_{1|2}}}^\infty\int_{-\frac{\mu_{3|2}}{\sigma_{3|2}}}^\infty
      \phi(z_1,z_3;\rho_{13|2})dz_1 dz_3} \\[8pt]
    \phantom{f_+(y)}={\displaystyle\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)}\\[12pt]
    \phantom{f_+(y)} \times{\displaystyle \Phi\left(\frac{\beta_1^\top x_1+\rho_{12}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma}}
        {\sqrt{1-\rho_{12}^2}},\frac{\beta_3^\top x_3+\rho_{23}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma}}
        {\sqrt{1-\rho_{23}^2}};\rho_{13|2}\right)}.
  \end{array}
  \end{equation}


\item For trivariate hurdle model 6, we proceed as for hurdle model 8
  by substituting the joint normal density function~(\ref{eq13}), by
  the following joint normal/log-normal density function:

  \begin{equation}\label{eq17}
  \frac{1}{\sigma y}\phi\left(y_1^*-\beta_1^\top x_1,\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}
  {\sigma},y_3^*-\beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right).
  \end{equation}

  To integrate this density function with respect to the positive values of
  $y_1^*$ and $y_2^*$, we rewrite it as the product of the marginal distribution
  of $y$, which is log-normal:

  \begin{equation}\label{eq18}
  \frac{1}{\sigma y}\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}\right)
  \end{equation}

  and of the joint density function of $y_1^*|y$ and $y_3^*|y$, which is bivariate normal:

  \begin{equation}\label{eq19}
  \frac{1}{\sigma_{1|2}\sigma_{3|2}}\phi\left(\frac{y_1^*-\mu_{1|2}}{\sigma_{1|2}},
  \frac{y_3^*-\mu_{3|2}}{\sigma_{3|2}}; \rho_{13|2}\right),
  \end{equation}
  with:
  $$
  \mu_{1|2}=\beta_1^\top x_1+\rho_{12}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}, \quad
  \mu_{3|2}=\beta_3^\top x_3+\rho_{23}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma},
  $$
  $$
  \sigma_{1|2}^2=1-\rho_{12}^2, \quad \sigma_{3|2}^2=1-\rho_{23}^2, \quad
  \rho_{13|2}=\frac{\rho_{13}-\rho_{12}\rho_{23}}{\sqrt{1-\rho_{12}^2}\sqrt{1-\rho_{23}^2}}.
  $$

  By integrating this factorisation of the density function of $y_1^*$, $y$ and $y_3^*$,
  over the positive values of $y_1^*$ and $y_3^*$, we obtain:

  \begin{equation}\label{eq20}
  \begin{array}{l}
    f_+(y)={\displaystyle\frac{\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}\right)}{\sigma y}
      \int_{-\frac{\mu_{1|2}}{\sigma_{1|2}}}^\infty\int_{-\frac{\mu_{3|2}}{\sigma_{3|2}}}^\infty
      \phi(z_1,z_3;\rho_{13|2})dz_1 dz_3} \\[8pt]
    \phantom{f_+(y)}={\displaystyle\frac{\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}\right)}{\sigma y}}\\[8pt]
    \phantom{f_+(y)}\times{\displaystyle\Phi\left(\frac{\beta_1^\top x_1+\rho_{12}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}}
        {\sqrt{1-\rho_{12}^2}},\frac{\beta_3^\top x_3+\rho_{23}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}}
        {\sqrt{1-\rho_{23}^2}};\rho_{13|2}\right)}.
  \end{array}
  \end{equation}

\item The density function $f_+(y)$ for bivariate hurdle models 7 and
  5 and univariate hurdle model 3 can be derived from that of
  trivariate model 8 by eliminating hurdles 1, 3, 1 and 3,
  respectively.  Likewise, this density function for bivariate hurdle
  models 4 and 2 can be derived from that of trivariate hurdle model 6
  by eliminating hurdles 1 and 3, respectively.  Corresponding
  formulas for $f_+(y)$ for all this special cases implemented in
  \proglang{R} are presented in Table~\ref{tab:typo}.
\end{itemize}

From these results it is easy to derive the likelihood function of a
random sample of $n$ observations of the censored dependent variable
$y$.  As these observations are all independently drawn from the same
conditional (on covariates $x_1$, $x_2$ and $x_3$) discrete-continuous
distribution, which assigns a conditional probability mass $P(y=0)$ to
the observed value $y=0$ and a conditional density function $f_+(y)$
to the observed values $y>0$, the log-likelihood function for an
observation $y_i$ can be written as :

\begin{equation}\label{eq21}
\ln L_i = \left\{
  \begin{array}{ll}
    \ln P(y_i=0) & \mbox{if} \quad y_i=0 \\
    \ln f_+(y_i) & \mbox{if} \quad y_i>0
\end{array}
\right.
\end{equation}

and the log-likelihood for the entire random sample:

\begin{equation}\label{eq22}
  \ln L = \sum_{i=1}^n \ln L_i= \sum_{i \mid y_i = 0} \ln P(y_i=0) + \sum_{i \mid y_i > 0} \ln f_+(y_i).
\end{equation}



\section{Model estimation, evaluation and selection}
\label{sec:estevalsel}

The econometric framework described in the previous section provides a
theoretical background for tackling the problems of model estimation,
evaluation and selection within the statistical theory of classical
inference.

\subsection{Model estimation}

The full parametric specification of our multiple hurdle models allows
to efficiently estimate their parameters by means of the maximum
likelihood principle. Indeed, it is well known from classical
estimation theory that, under the assumption of a correct model
specification and for a likelihood function sufficiently well behaved,
the maximum likelihood estimator is asymptotically efficient within
the class of consistent and asymptotically normal estimators
\footnote{See \citet{AMEM/85} chapter 4, for a more rigorous statement
  of this property.}.

More precisely, the asymptotic distribution of the maximum likelihood
estimator $\hat{\theta}$ for the parameter vector $\theta$ of a
multiple hurdle model, is written as:

\begin{equation}\label{eq23}
  \hat{\theta} \overset{A}{\sim} N(\theta,\frac{1}{n} I_A (\theta)^{-1}),
\end{equation}

where $\overset{A}{\sim}$ stands for ``asymptotically distributed as''
and

\begin{equation*}
  I_A(\theta)=\mbox{plim} \frac{1}{n} \sum_{i=1}^n E\left(\frac{\partial^2
      \ln L_i (\theta)}{\partial \theta \partial \theta^\top}\right)
  =\mbox{plim} \frac{1}{n} \sum_{i=1}^n E\left(\frac{\partial\ln
      L_i(\theta)}{\partial\theta} \frac{\partial\ln L_i
      (\theta)}{\partial\theta^\top}\right)
\end{equation*}

for the asymptotic Fisher information matrix of a sample of $n$
independent observations.

More generally, any inference about a differentiable vector function
of $\theta$, denoted by $\gamma=h(\theta)$, can be based on the
asymptotic distribution of its implied maximum likelihood estimator
$\hat{\gamma}=h(\hat{\theta})$.  This distribution can be derived from
the asymptotic distribution of $\hat{\theta}$ according to the so
called delta method:

\begin{equation}\label{eq24}
\hat{\gamma} \overset{A}{\sim} h(\theta)+\frac{\partial
  h}{\partial\theta^\top} (\hat\theta-\theta) \overset{A}{\sim}
N\left(\gamma,\frac{1}{n} \frac{\partial h}{\partial\theta^\top}I_A
(\theta)^{-1}\frac{\partial h^\top}{\partial\theta}\right).
\end{equation}

The practical use of these asymptotic distributions requires to
replace the theoretical variance-covariance matrix of these asymptotic
distributions with consistent estimators, which can be obtained by
using $\frac{\partial h (\hat{\theta})}{\partial\theta^\top}$ as a
consistent estimator for $\frac{\partial h
  (\theta)}{\partial\theta^\top}$ and either $\frac{1}{n} \sum_{i=1}^n
\frac{\partial^2\ln L_i
  (\hat{\theta})}{\partial\theta\partial\theta^\top}$ or $\frac{1}{n}
\sum_{i=1}^n \frac{\partial\ln L_i(\hat{\theta})}{\partial\theta}
\frac{\partial\ln L_i (\hat{\theta})}{\partial\theta^\top}$ as a
consistent estimator for $I_A(\theta)$. The last two estimators are
directly provided by two standard iterative methods used to compute
the maximum likelihood parameter's estimate, namely the Newton-Raphson
method and the Berndt, Hall, Hall, Hausman or \textsc{bhhh} method,
respectively, mentioned in section 4.3.

\subsection{Model evaluation and selection using goodness of fit measures}

Two fundamental principles should be used to appraise the results of a
model estimation, namely its economic relevance and its statistical
and predictive adequacy. The first principle deals with the issues of
accordance of model estimate with the economic rationale underlying
the model specification and of its relevance for answering the
questions for which the model has been built. These issues are
essentially context specific and, therefore, cannot be dealt with by
means of generic criteria.  The second principle refers to the issues
of empirical soundness of model estimate and of its ability to predict
sample or out-of-sample observations.  These issues can be tackled by
means of formal tests of significance, based on the previously
presented asymptotic distributions of model estimates, and by measures
of goodness of fit/prediction, respectively.

To assess the goodness of fit of \pkg{mhurdle} estimates, two pseudo
$R^2$ coefficients are provided. The first one is an extension of the
classical coefficient of determination, used to explain the fraction
of variation of the dependent variable explained by the covariates
included in a linear regression model with intercept. The second one
is an extension of the likelihood ratio index introduced
by~\citet{MCFA/74} to measure the relative gain in the maximised
log-likelihood function due to the covariates included in a
qualitative response model.

To define a pseudo coefficient of determination, we rely on the non
linear regression model explaining the dependent variable of a
multiple hurdle model. This model is written as:

\begin{equation}\label{eq25}
y=E(y)+u,
\end{equation}

where $u$ stands for a zero expectation, heteroskedastic random
disturbance and $E(y)$ for the expectation of the censored dependent
variable $y$:

\begin{equation}\label{eq26}
  E(y)=0 \times P(y=0)+\int_0^\infty yf_+(y)dy=\int_0^\infty yf_+(y)dy.
\end{equation}

To compute this expectation, we reformulate it as a multiple integral
of the joint density function of $y_1^*$, $y$ and $y_3^*$ multiplied
by $y$, over the positive values of these variables.

\begin{itemize}

\item For trivariate hurdle model 8, using the density function
  ~(\ref{eq13}) and the change of variables:

  \begin{equation}\label{eq27}
  \left\{
  \begin{array}{l}
   z_1 = y_1^* - \beta_1^\top x_1 \\[4pt]
   z_2 = {\displaystyle\frac{\Phi_3 y - \beta_2^\top x_2}{\sigma}} \\[8pt]
   z_3 = y_3^* - \beta_3^\top x_3
  \end{array}
  \right.
  \end{equation}

  this reformulation of $E(y)$ is written as:

  \begin{equation}\label{eq28}
  \begin{array}{l}
  E(y)={\displaystyle\int_{-\beta_1^\top x_1}^\infty \int_{-\frac{\beta_2^\top x_2}{\sigma}}^\infty
   \int_{-\beta_3^\top x_3}^\infty \frac{\beta_2^\top x_2+\sigma z_2}{\Phi_3}
   \phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right) dz_1 dz_2 dz_3} \\[16pt]
 \phantom{E(y)} ={\displaystyle\frac{\beta_2^\top x_2}{\Phi_3}\Phi\left(\beta_1^\top x_1,\frac{\beta_2^\top x_2}{\sigma},
   \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)} \\[12pt]
  \phantom{E(y)}+{\displaystyle\frac{\sigma}{\Phi_3}
   \int_{-\beta_1^\top x_1}^\infty \int_{-\frac{\beta_2^\top x_2}{\sigma}}^\infty
   \int_{-\beta_3^\top x_3}^\infty z_2\phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right) dz_1 dz_2 dz_3}.
  \end{array}
  \end{equation}

  To perform the analytical integration of the second term of the right-hand side
  of this formula, it is useful to rewrite the density function of $z_1$, $z_2$
  and $z_3$ as the product of the marginal density function of $z_1$ and $z_2$, namely
  $\phi\left(z_1,z_2;\rho_{13}\right)$ and of the density function of $z_2|z_1,z_3$,
  which can be written as follows:

  \begin{equation}\label{eq29}
  \frac{\phi\left(\frac{z_2-\mu_{2|1,3}}{\sigma_{2|1,3}}\right)}{\sigma_{2|1,3}},
  \end{equation}

  where:
  $$
  \mu_{2|1,3}=\varrho_1 z_1 + \varrho_3 z_3, \quad
  \sigma_{2|1,3}^2=\frac{1-\rho_{12}^2-\rho_{13}^2-\rho_{23}^2+2\rho_{12}\rho_{13}\rho_{23}}
  {1-\rho_{13}^2},
  $$
  with:
  $$
  \varrho_1=\frac{\rho_{12}-\rho_{13}\rho_{23}}{1-\rho_{13}^2}, \quad
  \varrho_3=\frac{\rho_{23}-\rho_{12}\rho_{13}}{1-\rho_{13}^2}.
  $$

  Using this factorisation of the density function of $z_1$, $z_2$ and $z_3$,
  we obtain:

  \begin{equation}\label{eq30}
  \begin{array}{l}
  {\displaystyle\int_{-\beta_1^\top x_1}^\infty \int_{-\frac{\beta_2^\top x_2}{\sigma}}^\infty
  \int_{-\beta_3^\top x_3}^\infty z_2\phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right)
  dz_1 dz_2 dz_3}\\[12pt]
  ={\displaystyle\int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty
  \left[\int_{-\frac{\beta_2^\top x_2}{\sigma}}^\infty z_2\phi\left(\frac{z_2-\mu_{2|1,3}}
  {\sigma_{2|1,3}}\right)\frac{dz_2}{\sigma_{2|1,3}}\right]\phi\left(z_1,z_2;\rho_{13}\right)dz_1 dz_3}.
  \end{array}
  \end{equation}

  By performing the change of variable:

  \begin{equation}\label{eq31}
  z=\frac{z_2 - \mu_{2|1,3}}{\sigma_{2|1,3}},
  \end{equation}

  the integral with respect to $z_2$ simplifies to:

  \begin{equation}\label{eq32}
  \mu_{2|1,3}\Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\mu_{2|1,3}}{\sigma_{2|1,3}}\right)
  +\sigma_{2|1,3}\phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\mu_{2|1,3}}{\sigma_{2|1,3}}\right).
  \end{equation}

  By inserting this result in formula~(\ref{eq30}), we finally obtain:

  \begin{equation}\label{eq33}
  \begin{array}{l}
  E(y)=\displaystyle\frac{\beta_2^\top x_2}{\Phi_3 }\Phi\left(\beta_1^\top x_1,\frac{\beta_2^\top x_2}{\sigma},
  \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)\\[8pt]
\displaystyle \phantom{E(y)} + \frac{\sigma}{\Phi_3}
  \int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty \left[\left(\varrho_1 z_1+\varrho_3 z_3 \right)
  \Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}
  +\varrho_1 z_1+\varrho_3 z_3}{\sigma_{2|1,3}}\right)\right.\\[16pt]
\left.\phantom{E(y)}+\sigma_{2|1,3}
  \phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\varrho_1 z_1+\varrho_3 z_3}{\sigma_{2|1,3}}\right)
  \right]\phi\left(z_1,z_3;\rho_{13}\right) dz_1 dz_3.
  \end{array}
  \end{equation}

\item For trivariate hurdle model 6, we proceed as for hurdle model 8
  by first substituting the joint normal density function~(\ref{eq13})
  by the joint normal/log-normal density function~(\ref{eq17}), then
  by performing the change of variables:

  \begin{equation}\label{eq34}
  \left\{
  \begin{array}{l}
   z_1 = y_1^* - \beta_1^\top x_1 \\[4pt]
   z_2 = {\displaystyle\frac{\ln\left(\Phi_3 y\right) - \beta_2^\top x_2}{\sigma}} \\[12pt]
   z_3 = y_3^* - \beta_3^\top x_3
  \end{array}
  \right.
  \end{equation}

  This leads to the following expression of the expected value of $y$:

  \begin{equation}\label{eq35}
  \begin{array}{l}
  E(y)=\displaystyle\int_{-\beta_1^\top x_1}^\infty \int_{-\infty}^\infty
  \int_{-\beta_3^\top x_3}^\infty \frac{\exp\{\beta_2^\top x_2+\sigma z_2\}}{\Phi_3} \\
\displaystyle  \times   \phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right) dz_1 dz_2 dz_3
  \displaystyle =\frac{\exp\{\beta_2^\top x_2\}}{\Phi_3}\\[12pt]
\displaystyle \times \int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty \left[\int_{-\infty}^\infty \exp\{\sigma z_2\}\phi\left(\frac{z_2-\mu_{2|1,3}}  {\sigma_{2|1,3}}\right)\frac{dz_2}{\sigma_{2|1,3}} \right] \phi\left(z_1,z_3;\rho_{13}\right)dz_1 dz_3
  \end{array}
  \end{equation}

  obtained by factorising the density function of $z_1$, $z_2$ and $z_3$
  as the product of the marginal density function of $z_1$ and $z_3$
  times the density function of $z_2|z_1,z_3$.\\
  By performing the change of variable~(\ref{eq31}),
  the integral with respect to $z_2$ simplifies to:

  \begin{equation}\label{eq36}
  \int_{-\infty}^\infty \exp\{\sigma (\mu_{2|1,3}+\sigma_{2|1,3}z)\}\phi(z)dz
  =\exp\left\{\sigma\mu_{2|1,3}+\frac{\sigma^2\sigma_{2|1,3}^2}{2}\right\}.
    \end{equation}

  By inserting this result in formula~(\ref{eq35}), we finally obtain:

  \begin{equation}\label{eq37}
 \begin{array}{l}
\displaystyle  E(y)=\frac{\exp\left\{\beta_2^\top x_2+\frac{\sigma^2\sigma_{2|1,3}^2}{2}\right\}}
  {\Phi_3}\\[12pt]
\displaystyle \phantom{E(y)} \times \int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty
  \exp\{\sigma\left(\varrho_1 z_1+\varrho_3 z_3 \right)\}
  \phi\left(z_1,z_3;\rho_{13}\right)dz_1dz_3.
\end{array}
  \end{equation}

\item $E(y)$ for bivariate hurdle models 7 and 5 and
  univariate hurdle model 3 can be derived from that of trivariate model 8
  by eliminating hurdles 1, 3, 1 and 3, respectively.
  Likewise, the expectation of $y$ for bivariate hurdle models 4 and 2 can be derived
  from that of trivariate hurdle model 6 by eliminating hurdles 1 and 3, respectively.
  Corresponding formulas of $E(y|y>0)= E(y)/P(y>0)$ for all this special cases implemented in
  \proglang{R} are presented in Table~\ref{tab:typo}, using the following notations:
  $$
  \Psi_{2|1}=\rho_{12}\phi_1\Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}
  -\rho_{12}\beta_1^\top x_1}{\sqrt{1-\rho_{12}^2}}\right)+\phi_2\Phi\left(\frac{\beta_1^\top x_1
  -\rho_{12}\frac{\beta_2^\top x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right),
  $$
  $$
  \Psi_{2|3}=\rho_{23}\phi_3\Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}
  -\rho_{23}\beta_3^\top x_3}{\sqrt{1-\rho_{23}^2}}\right)+\phi_2\Phi\left(\frac{\beta_3^\top x_3
  -\rho_{23}\frac{\beta_2^\top x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right),
  $$
  where $\phi_1=\phi(\beta_1^\top x_1)$, $\phi_2\left(\frac{\beta_2^\top x_2}{\sigma}\right)$ and
  $\phi_3=\phi(\beta_3^\top x_3)$.

  Note that formulas of $E(y|y>0)$ for dependent trivariate hurdle models presented
  in Table~\ref{tab:typo} are obtained by using closed forms of the
  following integrals :
  $$
  \int_{-\beta^\top x}^\infty\left[\rho z\Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\rho z}
  {\sqrt{1-\rho^2}}\right)+\sqrt{1-\rho^2}\phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\rho z}
  {\sqrt{1-\rho^2}}\right)\right]\phi(z)dz
  $$
  $$
  =\rho\phi\left(\beta^\top x\right)\Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}
  -\rho\beta^\top x}{\sqrt{1-\rho^2}}\right)+\phi\left(\frac{\beta_2^\top x_2}{\sigma}\right)
  \Phi\left(\frac{\beta^\top x-\rho\frac{\beta_2^\top x_2}{\sigma}}{\sqrt{1-\rho^2}}\right),
  $$
  $$
  \int_{-\beta^\top x}^\infty \exp\left\{\sigma\rho z\right\}\phi(z)dz=
  \exp\left\{\frac{\sigma^2\rho^2}{2}\right\}\Phi\left(\beta^\top x+\sigma\rho\right).
  $$

\end{itemize}

Denoting by $\hat{y}_i$ the fitted values of $y_i$ obtained by
estimating the mean square error predictor $E(y_i)$ for $y_i$ with the
maximum likelihood estimate of model parameters, we define a pseudo
coefficient of determination for a multiple hurdle model using the
following formula:

\begin{equation}\label{eq38}
R^2=1-\frac{RSS}{TSS},
\end{equation}

with $RSS=\sum (y_i - \hat{y}_i)^2$ the residual sum of squares and
$TSS=\sum (y_i - \hat{y}_0)^2$ the total sum of squares, where
$\hat{y}_0$ denotes the maximum likelihood estimate of $E(y_i)$ in the
multiple hurdle model without covariates (intercept-only model
\footnote{For multiple hurdle models involving many intercepts, the
estimation of a specification without covariates may face serious
numerical problems. If the mhurdle software fails to provide such an
estimate, the total sum of squares $TSS$ is computed by substituting
the sample average of $y$ for $\hat{y}_0$.}). Note that
this goodness of fit measure cannot exceed one but can be negative, as
a consequence of the non linearity of $E(y_i)$ with respect to the
parameters.

The extension of the McFadden likelihood ratio index for qualitative
response models to multiple hurdle models is straightforwardly
obtained by substituting in this index formula:

\begin{equation}\label{eq40}
\rho^2=1-\frac{\ln L(\hat{\theta})}{\ln L(\hat{\alpha})}=\frac{\ln
L(\hat{\alpha})-\ln L(\hat{\theta})}{\ln L(\hat{\alpha})},
\end{equation}

the maximised log-likelihood function of a qualitative response model
with covariates and the log-likelihood function of the corresponding
model without covariates or intercept-only model, with the maximised
log-likelihood functions of a multiple hurdle model with covariates,
$\ln L(\hat{\theta})$, and without covariates, $\ln L(\hat{\alpha})$,
respectively.  This goodness of fit measure takes values within zero
and one and, as it can be easily inferred from the above second
expression of $\rho^2$, it measures the relative increase of the
maximised log-likelihood function due to the use of explanatory
variables with respect to the maximised log-likelihood function of a
naive intercept-only model.

Model selection deals with the problem of discriminating between
alternative model specifications used to explain the same dependent
variable, with the purpose of finding the one best suited to explain
the sample of observations at hand.  This decision problem can be
tackled from the point of view of the model specification achieving
the best in-sample fit.

This selection criterion is easy to apply as it consists in comparing
one of the above defined measures of fit, computed for the competing
model specifications, after adjusting them for the loss of sample
degrees of freedom due to model parametrisation.  Indeed, the value of
these measures of fit can be improved by increasing model
parametrisation, in particular when the parameter estimates are
obtained by optimising a criteria functionally related to the selected
measure of fit, as is the case when using the $\rho^2$ fit measure
with a maximum likelihood estimate. Consequently, a penalty that
increases with the number of model parameters should be added to the
$R^2$ and $\rho^2$ fit measures to trade off goodness of fit
improvements with parameter parsimony losses.

To define an adjusted pseudo coefficient of determination, we rely on
\citet{THEIL/73}'s correction of $R^2$ in a linear regression model,
defined by

\begin{equation}\label{eq41}
\bar{R}^2=1-\frac{n-K_0}{n-K}\frac{RSS}{TSS},
\end{equation}

where $K$ and $K_0$ stand for the number of parameters of the multiple
hurdle model with covariates and without covariates, respectively
\footnote{When the mhurdle software fails to provide the parameter 
estimates of the intercept-only model and the total sum of squares 
$TSS$ is computed by substituting the sample average of $y$ for 
$\hat{y}_0$, $K_0$ is set equal to 1.}. Therefore, choosing the 
model specification with the largest $\bar{R}^2$ is equivalent to 
choosing the model specification with the smallest model residual 
variance estimate: $s^2=\frac{RSS}{n-K}$.

To define an adjusted likelihood ratio index, we replace in this
goodness of fit measure $\rho^2$ the log-likelihood criterion with the
Akaike information criterion $AIC=-2\ln
L(\hat{\theta})+2K$. Therefore, choosing the model specification with
the largest

\begin{equation}\label{eq42}
\bar{\rho}^2=1-\frac{\ln L(\hat{\theta})-K}{\ln L(\hat{\alpha})-K_0}
\end{equation}

is equivalent to choosing the model specification that minimises the
\citet{AKAIKE/73} predictor of the Kullback-Leibler Information
Criterion (KLIC). This criterion measures the distance between the
conditional density function $f(y|x;\theta)$ of a possibly
misspecified parametric model and that of the true unknown model,
denoted by $h(y|x)$. It is defined by the following formula:

\begin{equation}\label{eq43}
KLIC=E\left[\ln
  \left(\frac{h(y|x)}{f(y|x;\theta_\ast)}\right)\right]=\int \ln
\left(\frac{h(y|x)}{f(y|x;\theta_\ast)}\right)dH(y,x),
\end{equation}

where $H(y,x)$ denotes the distribution function of the true joint
distribution of $(y,x)$ and $\theta_\ast$ the probability limit, with
respect to $H(y,x)$, of $\hat{\theta}$ the so called quasi-maximum
likelihood estimator obtained by applying the maximum likelihood when
$f(y|x;\theta)$ is misspecified.


\subsection{Model selection using Vuong tests}

Model selection can also be tackled from the point of view of the model
specification that is favoured in a formal test comparing two model
alternatives.

This second model selection criterion relies on the use of a test
proposed by \citet{VUONG/89}. According to the rationale of this test,
the "best" parametric model specification among a collection of
competing specifications is the one that minimises the $KLIC$
criterion or, equivalently, the specification for which the quantity:

\begin{equation}\label{eq44}
E[\ln f(y|x;\theta_\ast)]=\int \ln f(y|x;\theta_\ast)dH(y,x)
\end{equation}

is the largest. Therefore, given two competing conditional models with
density functions $f(y|x;\theta)$ and $g(y|x;\pi)$ and parameter
vectors $\theta$ and $\pi$ of size $K$ and $L$, respectively, Vuong
suggests to discriminate between these models by testing the null
hypothesis:

$$
H_0 : E[\ln f(y|x;\theta_\ast)]=E[\ln g(y|x;\pi_\ast)]
\Longleftrightarrow
E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]=0,
$$

meaning that the two models are equivalent, against:

$$
H_f : E[\ln f(y|x;\theta_\ast)]>E[\ln g(y|x;\pi_\ast)]
\Longleftrightarrow
E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]>0,
$$

meaning that specification $f(y|x;\theta)$ is better than
$g(y|x;\pi)$, or against:

$$
H_g : E[\ln f(y|x;\theta_\ast)]<E[\ln g(y|x;\pi_\ast)]
\Longleftrightarrow
E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]<0,
$$

meaning that specification $g(y|x;\pi)$ is better than $f(y|x;\theta)$.

The quantity $E[\ln f(y|x;\theta_\ast)]$ is unknown but it can be
consistently estimated, under some regularity conditions, by $1/n$
times the log-likelihood evaluated at the quasi-maximum likelihood
estimator. Hence $1/n$ times the log-likelihood ratio (LR) statistic

\begin{equation}\label{eq45}
LR(\hat{\theta},\hat{\pi})=\sum_{i=1}^n
\ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}
\end{equation}

is a consistent estimator of
$E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]$. Therefore,
an obvious test of $H_0$ consists in verifying whether the LR
statistic differs from zero.  The distribution of this statistic can
be worked out even when the true model is unknown, as the
quasi-maximum likelihood estimators $\hat{\theta}$ and $\hat{\pi}$
converge in probability to the pseudo-true values $\theta_\ast$ and
$\pi_\ast$, respectively, and have asymptotic normal distributions
centred on these pseudo-true values.

The resulting distribution of $LR(\hat{\theta},\hat{\pi})$ depends on
the relation linking the two competing models. To this purpose, Vuong
differentiates among three types of competing models, namely: nested,
strictly non nested and overlapping.

A parametric model $G_\pi$ defined by the conditional density function
$g(y|x;\pi)$ is said to be nested in parametric model $F_\theta$ with
conditional density function $f(y|x;\theta)$, if and only if any
conditional density function of $G_\pi$ is equal to a conditional
density function of $F_\theta$ almost everywhere (disregarding any
zero probability sub-set of $(y,x)$ values, with respect to the true
distribution function $H(y,x)$). This means that we can write a
parametric constraint in the form $\theta=T(\pi)$, allowing to express
model $G_\pi$ as a particular case of model $F_\theta$. Within our
multiple hurdle special models this is the case when comparing two
specifications differing only with respect to the presence or the
absence of correlated disturbances.  For these models, it is
necessarily the case that $f(y|x;\theta_\ast)\equiv
g(y|x;\pi_\ast)$. Therefore $H_0$ is tested against $H_f$.

If model $F_\theta$ is misspecified, it has been shown by Vuong that:

\begin{itemize}
\item under $H_0$, the quantity $2LR(\hat{\theta},\hat{\pi})$ converges
  in distribution towards a weighted sum of $K+L$ iid $\chi^2(1)$
  random variables, where the weights are the $K+L$ almost surely real
  and non negative eigenvalues of the following $(K+L) \times (K+L)$
  matrix:

  $$
  W=\left[ \begin{array}{c}
  -B_f A_f^{-1}\quad \  \quad -B_{fg} A_g^{-1} \\
  B_{fg}^\top A_f^{-1}\quad \ \quad\quad B_g A_g^{-1}
  \end{array} \right],
  $$

  where

  $$
  A_f=E\left(\frac{\partial^2\ln
      f(y|x;\theta_\ast)}{\partial\theta\partial\theta^\top}\right),\quad
  A_g=E\left(\frac{\partial^2\ln
      g(y|x;\pi_\ast)}{\partial\pi\partial\pi^\top}\right),
  $$
  $$
  B_f=E\left(\frac{\partial\ln
      f(y|x;\theta_\ast)}{\partial\theta}\frac{\partial\ln
      f(y|x;\theta_\ast)}{\partial\theta^\top}\right),\quad
  B_g=E\left(\frac{\partial\ln
      g(y|x;\pi_\ast)}{\partial\pi}\frac{\partial\ln
      g(y|x;\pi_\ast)}{\partial\pi^\top}\right),
  $$
  $$
  B_{fg}=E\left(\frac{\partial\ln
      f(y|x;\theta_\ast)}{\partial\theta}\frac{\partial\ln
      g(y|x;\pi_\ast)}{\partial\pi^\top}\right).
  $$

  To simplify the computation of this limiting distribution,
  one can alternatively use the weighted sum of $K$ iid
  $\chi^2(1)$ random variables, where the weights are the $K$
  almost surely real and non negative eigenvalues of the following
  smaller $K \times K$ matrix:

  $$
  \underline{W}=B_f\left[DA_g^{-1}D^\top -A_f^{-1}\right],
  $$

  where $D=\frac{\partial T(\pi_\ast)}{\partial\pi^\top}$.

\item under $H_f$, the same statistic converge almost surely towards
  $+\infty$.

\end{itemize}

Performing this standard LR test for nested models, requires to
replace the theoretical matrices $W$ and $\underline{W}$ by a
consistent estimator. Such an estimator is obtained by substituting
matrices $A_f$, $A_g$, $B_f$, $B_g$ and $B_{fg}$ for their sample
analogue:

$$
\hat{A}_f=\frac{1}{n}\sum_{i=1}^n\frac{\partial^2\ln
  f(y_i|x_i;\hat{\theta})}{\partial\theta\partial\theta^\top},\quad
\hat{A}_g=\frac{1}{n}\sum_{i=1}^n\frac{\partial^2\ln
  g(y_i|x_i;\hat{\pi})}{\partial\pi\partial\pi^\top},
$$
$$
\hat{B}_f=\frac{1}{n}\sum_{i=1}^n\frac{\partial\ln
  f(y_i|x_i;\hat{\theta})}{\partial\theta}\frac{\partial\ln f(y_i|x_i;
  \hat{\theta})}{\partial\theta^\top},\quad
\hat{B}_g=\frac{1}{n}\sum_{i=1}^n\frac{\partial\ln
  g(y_i|x_i;\hat{\theta})}{\partial\theta}\frac{\partial\ln g(y_i|x_i;
  \hat{\theta})}{\partial\theta^\top},
$$
$$
\hat{B}_{fg}=\frac{1}{n}\sum_{i=1}^n\frac{\partial\ln
  f(y_i|x_i;\hat{\theta})}{\partial\theta}\frac{\partial\ln g(y_i|x_i;
  \hat{\theta})}{\partial\theta^\top}
$$

and $D$ for $\hat{D}=\partial T(\hat{\pi})/\partial\pi^\top$.

The density function of this asymptotic test statistic has not
been worked out analytically. Therefore, we compute it by simulation.

Hence, for a test with critical value $c$, $H_0$ is rejected in favour
of $H_f$ if $2LR(\hat{\theta},\hat{\pi})>c$ or if the p-value
associated to the observed value of $2LR(\hat{\theta},\hat{\pi})$ is
less than the significance level of the test.

Note that, if model $F_\theta$ is correctly specified, the
asymptotic distribution of the LR statistic is, as expected, a
$\chi^2$ random variable with $K-L$ degrees of freedom.

Two parametric models $F_\theta$ and $G_\pi$ defined by conditional
distribution functions $f(y|x;\theta)$ and $g(y|x;\pi)$ are said to be
strictly non-nested, if and only if no conditional distribution
function of model $F_\theta$ is equal to a conditional distribution
function of $G_\pi$ almost everywhere, and conversely. Within multiple
hurdle special models this is the case when comparing two
specifications differing with respect either to the censoring
mechanisms in effect or to the functional form of the desired
consumption equation. For these models, it is necessarily the case
that $f(y|x;\theta_\ast)\neq g(y|x;\pi_\ast)$ implying that both
models are misspecified under $H_0$.

For such strictly non-nested models, Vuong has shown that:

\begin{itemize}
\item under $H_0$, the quantity $n^{-1/2}LR(\hat{\theta},\hat{\pi})$
  converges in distribution towards a normal random variable with zero
  expectation and variance:
 $$
 \omega^2=V\left(\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right)
 $$
 computed with respect to the distribution function of the true joint
 distribution of $(y,x)$.
\item under $H_f$, the same statistic converge almost surely towards
  $+\infty$.
\item under $H_g$, the same statistic converge almost surely towards
  $-\infty$.
\end{itemize}

Hence, $H_0$ is tested against $H_f$ or $H_g$ using the standardised
LR statistic:

\begin{equation}\label{eq46}
T_{LR}=\frac{LR(\hat{\theta},\hat{\pi})}{\sqrt{n}\hat{\omega}},
\end{equation}

where $\hat{\omega}^2$ denotes the following strongly consistent
estimator for $\omega^2$:

$$
\hat{\omega}^2=\frac{1}{n}\sum_{i=1}^n
\left(\ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}\right)^2
-\left(\frac{1}{n}\sum_{i=1}^n
  \ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}\right)^2 .
$$

As a consequence, for a test with critical value $c$, $H_0$ is
rejected in favour of $H_f$ if $T_{LR}>c$ or if the p-value associated
to the observed value of $T_{LR}$ in less than the significance level
of the test. Conversely, $H_0$ is rejected in favour of $H_g$ if
$T_{LR}<-c$ or if the p-value associated to the observed value of
$|T_{LR}|$ in less than the significance level of the test.

Note that, if one of models $F_\theta$ or $G_\pi$ is assumed to be
correctly specified, the \citet{COX/61,COX/62} LR test of non nested
models needs to be used. Because this test is computationally awkward
to implement and not really one of model selection, as it can lead to
reject both competing models, it has not been programmed in
\pkg{mhurdle}.

Two parametric models $F_\theta$ and $G_\pi$ defined by conditional
distribution functions $f(y|x;\theta)$ and $g(y|x;\pi)$ are said to be
overlapping, if and only if part of the conditional distribution
function of model $F_\theta$ is equal to the conditional distribution
function of $G_\pi$ but none of these models is nested in the
other. Within multiple hurdle special models this is the case when
comparing two specifications differing only with respect to the
covariates taken into consideration, some of them being common to
both models and others specific. For these models it is not clear
\emph{a priori} as to whether or not $f(y|x;\theta_\ast)=
g(y|x;\pi_\ast)$ almost everywhere, except if we know \emph{a priori}
that at least one of the two competing models is correctly
specified. As a consequence, the form of the asymptotic distribution
of $LR(\hat{\theta},\hat{\pi})$ under $H_0$ is unknown, which prevents
from performing a model selection test based on this statistic.

In the general case where both competing models are wrongly specified,
Vuong suggests a sequential procedure which consists in testing first
whether or not the variance $\omega^{2}$ equals zero (since
$f(y|x;\theta_\ast)= g(y|x;\pi_\ast)$ almost everywhere if and only if
$\omega^{2}=0$) and then, according to the outcome of this test, in
using the appropriate asymptotic $LR(\hat{\theta},\hat{\pi})$
distribution to perform the model selection test.

To test $H_0^{\omega}: \omega^2=0$ against $H_A^{\omega}: \omega^2\neq
0$, Vuong suggests to use, as a test statistic, the above defined
strongly consistent estimator for $\omega^2$, $\hat{\omega}^2$, and
proves that:

\begin{itemize}
\item under $H_0^{\omega}$, the quantity $n\hat{\omega}^2$ converges
  in distribution towards the same limiting distribution like that
  of statistic $2LR(\hat{\theta},\hat{\pi})$ when used for discriminating
  two misspecified nested models.

\item under $H_A^{\omega}$, the same statistic converge almost surely towards
  $+\infty$.
\end{itemize}

Therefore, performing this variance test requires to compute the
eigenvalues of a consistent estimate of matrix $W$ or $\underline{W}$,
and derive by simulation the density function of the corresponding
weighted sum of iid $\chi^2(1)$ random variables.

Hence, for a test with critical value $c$, $H_0^\omega$ is rejected in
favour of $H_A^\omega$ if $n\hat{\omega}^2>c$ or if the p-value
associated to the observed value of $n\hat{\omega}^2$ is less than the
significance level of the test.

Note, that an asymptotically equivalent test is obtained by replacing
in statistics $n\hat{\omega}^2$, $\hat{\omega}^2$ by:
$$
\tilde{\omega}^2=\frac{1}{n}\sum_{i=1}^n
\left(\ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}\right)^2.
$$

The second step in discriminating two overlapping models depends on
the outcome of the variance test.

\begin{itemize}
\item If $H_0^\omega$ is not rejected, one should conclude that the
  two models cannot be discriminated given the data, since assuming
  $\omega^2=0$ implies that $H_0$ means that the two models are
  equivalent.
\item If $H_0^\omega$ is rejected, the test of $H_0$ against $H_f$ or
  $H_g$ must be carried out using the standardised LR statistic
  $T_{LR}$, as for discriminating between two strictly non-nested
  models. Indeed, $H_0$ is still possible when $\omega^2\neq0$. Note,
  that this sequential procedure of testing $H_0$ against $H_f$ or
  $H_g$ has a significance level bounded above by the maximum of the
  significance levels used for performing the variance and the
  standardised LR tests.
\end{itemize}

Finally, if one of the two competing models is supposed to be
correctly specified, then the two models are equivalent if and only
if the other model is correctly specified and if and only if the
conditional density functions of the two models are identical almost
everywhere. In this case we can bypass the variance test and directly
construct a model selection test based on the
$2LR(\hat{\theta},\hat{\pi})$ test statistic used for discriminating
between two nested models.


\section{Software rationale}
\label{sec:software}

There are three important issues to be addressed to correctly
implement in \proglang{R} the modelling strategy described in the
previous sections. The first one is to provide a good interface to
describe the model to be estimated. The second one is to find
good starting values for computing model estimates. The third
one is to have flexible optimisation tools for likelihood
maximisation.

\subsection{Model syntax}
\label{sec:modeldesc}


In \proglang{R}, the model to be estimated is usually described using
formula objects, the left-hand side denoting the censored dependent
variable \texttt{y} and the right-hand side the functional relation
explaining \texttt{y} as a function of covariates. For example,
\texttt{y \~{} x1 + x2 * x3} indicates that \texttt{y} linearly depends
on variables \texttt{x1}, \texttt{x2}, \texttt{x3} and on the
interaction term \texttt{x2} times \texttt{x3}.

For the models implemented in \pkg{mhurdle}, three kinds of covariates
should be specified: those of the good selection equation (hurdle 1)
denoted $x_1$, those of the desired consumption equation (hurdle 2),
denoted $x_2$, and those of the purchasing equation (hurdle 3),
denoted $x_3$.

To define a model with three kinds of covariates, a general solution
is given by the \pkg{Formula} package developed by \citet{ZEIL/CROI/10},
which provides extended formula objects. To define a model where \texttt{y}
is the censored dependent variable, \texttt{x11} and \texttt{x12}
two covariates for the good selection equation, \texttt{x21} and \texttt{x22}
two covariates for the desired consumption equation, and \texttt{x31} and
\texttt{x32} two covariates for the purchasing equation, we use the
following commands :

<<>>=
library("Formula")
f <- Formula(y ~ x11 + x12  | x21 + x22 | x31 + x32)
@

\subsection{Starting values}
\label{sec:startvalues}

For the models we consider, the log-likelihood function will be, in
general, not concave. Moreover, this kind of models are highly non
linear with respect to parameters, and therefore difficult to
estimate. For these reasons, the question of finding good starting
values for the iterative computation of parameter estimates is
crucial.

As a less computer intensive alternative to maximum likelihood
estimation, \citet{HECKM/76} has suggested a two step estimation
procedure based on a respecification of the censored variable linear
regression model, sometimes called ``Heckit'' model, avoiding
inconsistency of the ordinary least-squares estimator.  This two step
estimator is consistent but inefficient. It is implemented in package
\pkg{sampleSelection} \citep{TOOME/HENNI/08}.

According to~\citet{CARL/CROI/HOAR/08} experience in applying this
estimation procedure to double hurdle models, this approach doesn't seem
to work well with correlated hurdle models. Indeed, except for the
very special case of models 2, 3 and 4, the probability of observing
a censored purchase is not that of a simple probit model
(see Table \ref{tab:typo}).

As noted previously, for uncorrelated single hurdle
models, the estimation may be performed in a sequence of two simple
estimations, namely the maximum likelihood estimation of a standard
dichotomous probit model, followed by the ordinary least-squares
estimation of a linear, log-linear or linear-truncated regression
model. In the last case, package \pkg{truncreg} \citep{TRUNCR/09} is
used.

For correlated single hurdle 1 model 2, the maximum likelihood
estimate of the parameters of the corresponding uncorrelated model
($\rho_{12}=0$) is used as starting values.

For P-Tobit models (4 and 7), the starting values are computed using
an Heckman-like two step procedure. In the first step, parameters
$\beta_3$ are estimated using a simple probit. In the second step, a
linear regression model is estimated by ordinary
least squares using the sub-sample of uncensored observations and
$y_i\Phi(\hat{\beta}_3^{\top}x_{3i})$ or $\ln y_i +\ln
\Phi(\hat{\beta}_3^{\top}x_{3i})$ (in the case of a log-normal
specification) as dependent variable.

For Tobit model (3), the least squares estimate of the linear regression
model is used as starting values.

For double hurdle model (5), the starting values for $\beta_1$ are
obtained by estimating a probit model and those for $\beta_2$ using
a least squares estimate with the truncated sample of a linear regression
model assuming $\rho_{12}=0$.

Finally, for models involving hurdles 1 and 3 (models 6 and 8), we
use two probit models to get starting values for $\beta_1$ and
$\beta_2$. Then, we estimate a linear regression model
by ordinary least squares with the sub-sample of uncensored observations
using $y_i\Phi(\hat{\beta}_3^{\top}x_{3i})$ or $\ln y_i +\ln
\Phi(\hat{\beta}_3^{\top}x_{3i})$ (in the case of a log-normal
specification) as dependent variable and
assuming no correlation between the desired consumption equation
and these two hurdles.

\subsection{Optimisation}
\label{sec:optimisation}

Two kinds of algorithms are currently used for maximum likelihood
estimation. The first kind of algorithms can be called ``Newton-like'' methods.
With these algorithms, at each iteration, the hessian
matrix of the log-likelihood is computed, using either the second derivatives
of the log-likelihood (Newton-Raphson method) or the outer product of the
gradient (Berndt, Hall, Hall, Hausman or \textsc{bhhh} method). This approach
is very powerful if the log-likelihood is well-behaved, but it may
perform poorly otherwise and fail after a few iterations.

The second algorithm, called Broyden, Fletcher, Goldfarb, Shanno or
\textsc{bfgs} method, updates at each iteration an estimate of the
hessian matrix of the log-likelihood. It is often more robust and may perform
better in cases where the formers don't work.

Two optimisation functions are included in core \proglang{R}:
\code{nlm}, which uses the Newton-Raphson method, and \code{optim} ,
which uses the \textsc{bfgs} method (among others). The recently developed
\pkg{maxLik} package by \citet{MAXLIK/08} provides a unified
framework. With a unique interface, all the previously described
methods are available.

The behaviour of \code{maxLik} can be controlled by the user using
\code{mhurdle} arguments like \texttt{print.level} (from 0-silent to
2-verbal), \texttt{iterlim} (the maximum number of iterations),
\texttt{methods} (the method used, one of \texttt{"nr"},
\texttt{"bhhh"} or \texttt{"bfgs"}) that are passed to \code{maxLik}.

Some models require the computation of the bivariate normal
cumulative density function. We use the \pkg{pbivnorm} package
\citep{KENKE:11} which provides a vectorised (and therefore fast
convenient) function to compute the bivariate normal cdf.


\section{Examples}
\label{sec:examples}

The package is loaded using:


<<>>=
library("mhurdle")
@

To illustrate the use of \pkg{mhurdle}, we use the \code{Comics} data
frame which contains data about the readings of comics. It is part of
a survey conducted by the \textsc{insee} (the French national
statistical institute) in 2003 about cultural and sportive
practises\footnote{The data is available at
  \url{http://insee.fr/fr/themes/detail.asp?reg_id=0&ref_id=fd-parcul03}. Main
  results are presented in \citet{MULL/05}.}. The explained variable
is the number of comics read during the last 12 months by one
(randomly chosen) member of the household. There are 5159
observations.


We emphasise that the observed censored variable to be explained is
not an expenditure but a service derived from the use of a durable
good, namely the comic book library to which the comic book reader has
access. Therefore, hurdles 2 and 3 of our modelling paradigm must be
reinterpreted as mechanisms describing the process of building up the
comic book library and that of planning the intensity of use of the
library, respectively.  Note also that \pkg{mhurdle} treats the
dependent variable as a continuous quantitative variable, while it is
in fact a discrete count variable. However, the high number of
readings during a year by a comic book reader fully justifies this
numerical approximation.


<<>>=
data("Comics", package = "mhurdle")
head(Comics, 3)
mean(Comics$comics == 0)
max(Comics$comics)
@

The number of comics read is zero for about 78\% of the sample and the
maximum value is 520. The covariates of this data frame are :

\begin{description}
\item[area:] one of \code{rural}, \code{small}, \code{medium},
  \code{large} and \code{paris}
\item[income:] the income of the household (in thousands of euros per
  month),
\item[cu:] the number of consumption units (one for the first two
  adults, one half for other members of the household),
\item[size :] the number of persons in the household,
\item[age : ] the age of the person,
\item[empl : ] the kind of occupation, a qualitative factor with 9 levels,
\item[gender: ] one of \code{male} and \code{female},
\item[couple,] "does the person live in couple ?", a qualitative factor with
  levels \code{yes} and \code{no},
\item[educ : ] the number of years of education.
\end{description}


\subsection{Estimation}

The estimation is performed using the \code{mhurdle} function, which
has the following arguments:

\begin{description}
\item[formula:] a formula describing the model to estimate. It should
  have three parts on the right-hand side specifying, in the first
  part, the good selection equation covariates, in the second part,
  the desired consumption equation covariates and, in the third part,
  the purchasing equation covariates.
\item[data:] a data frame containing the observations of the variables
  present in the formula.
\item[subset, weights, na.action:] these are arguments passed on to
  the model.frame function in order to extract the data suitable for
  the model. These arguments are present in the \code{lm} function and
  in most of the estimation functions.
\item[start:] the starting values. If \code{NULL}, the starting values
  are computed as described in section 4.2.
\item[dist:] this argument indicates the functional form of the
  desired consumption equation, which may be either log-normal
  \code{"l"} (the default), normal \code{"n"} or truncated normal
  \code{"t"}.
\item[corr:] this argument indicates whether the disturbance of the
  good selection equation (hurdle 1) or that of the purchasing
  equation (hurdle 3) is correlated with that of the desired
  consumption equation.  This argument is in this case respectively
  equal to \code{"h1"} or \code{"h3"}, or \code{NULL} (the default) in
  case of no correlation,
\item[...] further arguments that are passed to the optimisation
  function \code{maxLik}.
\end{description}

Different combinations of these arguments lead to a large variety of
models. Note that some of them are logically inconsistent and
therefore irrelevant. For example, a model with no good selection
equation and \code{corr = "h1"} is logically inconsistent.

To illustrate the use of \pkg{mhurdle} package, we first estimate a
simple Tobit model, which we call \code{model3} ; the income is first
divided by the number of consumption units and then by its sample
mean. Powers up to three for the log of income are introduced.

<<>>=
Comics$incu <- with(Comics, income / cu)
Comics$incum <- with(Comics, incu / mean(incu))


model3 <- mhurdle(comics ~ 0 | log(incum) + I(log(incum)^2) +
                  I(log(incum)^3) + age  + gender + educ +
                  size| 0, Comics, dist = "n", method = 'bfgs')
@

Note that the first and the third part of the formula are 0,
as there is no good selection and no purchasing equations.

Consider now that some covariates explain the fact that the good is
selected, and not the level of consumption if the good is chosen. In
this case, we estimate the following dependent double hurdle model, which
we call \code{model5d}. We keep the income and the size of the
household as covariates for the desired consumption equation and move the
other covariates to the first part of the formula.

<<>>=
model5d <- mhurdle(comics ~ gender + educ + age |  log(incum) +
                   I(log(incum)^2) + I(log(incum)^3) + size | 0,
                   Comics, corr = "h1", dist = "n", method = 'bfgs')
@

The same model without correlation is called \code{model5i}, and can
easily be obtained by updating \code{model5d} :


<<>>=
model5i <- update(model5d, corr = NULL)
@

If one wants that zeros only arise from the selection mechanism,
one has to switch the \code{dist} argument to \code{"l"}, so
that a log-normal distribution is introduced. This can be done easily
by updating the previous model and this leads to a model called
\code{model2d} :

<<>>=
model2d <- update(model5d, dist = "l")
@

The independent version is then easily obtained :

<<>>=
model2i <- update(model2d, corr = NULL)
@

The last model we estimate is a dependent triple hurdle model ;
compared to the double hurdle model previously estimated, we move the
\code{age} covariate from the selection to the purchasing equation :

<<>>=
model8d1 <- mhurdle(comics ~ gender + educ  |  log(incum) +
                    I(log(incum)^2) + I(log(incum)^3) + size | age,
                    Comics, corr = "h1", dist = "n", method = 'bfgs')
@


\subsection{Methods}

A \code{summary} method is provided for \code{mhurdle} objects :


<<>>=
summary(model8d1)
@

This method displays the percentage of 0 in the sample, the
table of parameter estimates, and two measures of goodness of fit.

\code{coef}, \code{vcov}, \code{logLik}, \code{fitted} and
\code{predict} methods are provided in order to extract part of the
results.

Parameter estimates and the estimated asymptotic variance matrix of maximum
likelihood estimators are extracted using the usual \code{coef} and
\code{vcov} functions. \code{mhurdle} object methods have a second
argument indicating which subset has to be returned (the default is to
return all).

<<>>=
coef(model8d1, "h2")
coef(model5d, "h1")
coef(model5d, "sigma")
coef(summary(model8d1), "h3")
vcov(model8d1, "h3")
@

Log-likelihood may be obtained for the estimated model or for a
``naive'' model, defined as a model without covariates :


<<>>=
logLik(model5d)
logLik(model5d, naive = TRUE)
@

Fitted values are obtained using the \code{fitted} method.  The output
is a matrix whose two columns are the estimated probability of
censoring $\mbox{P}(y=0)$ and the estimated expected value of an
uncensored dependent variable observation $\mbox{E}(y|y>0)$.


<<>>=
head(fitted(model5d))
@

A \code{predict} function is also provided, which returns the same
two columns for given values of the covariates.


<<>>=
predict(model5d,
        newdata = data.frame(
          comics = c(0, 1, 2),
          gender = c("female", "female", "male"),
          age = c(20, 18, 32),
          educ = c(10, 20, 5),
          incum = c(4, 8, 2),
          size = c(2, 1, 3)))
@

For model evaluation and selection purposes, goodness of fit measures
and Vuong tests described in section 3 are provided. These criteria
allow to select the most empirically relevant model specification.

Two goodness of fit measures are provided. The first measure is an
extension to limited dependent variable models of the classical
coefficient of determination for linear regression models. This pseudo
coefficient of determination is computed both without (see
formula~(\ref{eq38})) and with (see formula~(\ref{eq41})) adjustment for
the loss of sample degrees of freedom due to model parametrisation.
The unadjusted coefficient of determination allows to compare the
goodness of fit of model specifications having the same number of
parameters, whereas the adjusted version of this coefficient is suited
for comparing model specifications with a different number of
parameters.


<<>>=
rsq(model5d, type = "coefdet")
@

The second measure is an extension to limited dependent variable
models of the likelihood ratio index for qualitative response
models. This pseudo coefficient of determination is also computed both
without (see formula~(\ref{eq40})) and with (see formula~(\ref{eq42}))
adjustment for the loss of sample degrees of freedom due to model
parametrisation, in order to allow model comparisons with the same
or with a different number of parameters.


<<>>=
rsq(model5d, type = "lratio", adj = TRUE)
@

The Vuong test based on the $T_{LR}$ statistic, as presented in
section 3.3 (see formula~(\ref{eq46})), is also provided as a criteria
for model selection within the family of 8 strictly non-nested
models of Figure 1.


<<>>=
vuongtest(model5d, model8d1)
@

According to this outcome, the null hypothesis stating the equivalence
between the two models is strongly rejected in favour of the alternative
hypothesis stating that \code{model5d} is better than \code{model8d1}.

Note that Vuong tests for strictly non-nested mhurdle models can also
be performed using the vuong() function of the pscl package of
\citet{JACKM:11} .

Testing the hypothesis of no correlation between the good selection
mechanism and the desired consumption equation can be performed as a
Vuong test of selection between two nested models, differing only with
respect to the value of the correlation coefficient $\rho_{12}$,
namely the test of the hypothesis $H_0: \rho_{12}=0$, specifying an
independent mhurdle model, against the alternative hypothesis $H_a:
\rho_{12}\neq0$, specifying a corresponding dependent mhurdle
model. This test is performed using the log-likelihood ratio (LR)
statistic~(\ref{eq45}). As explained in section 3.3, the critical
value or the p-value to be used to perform this test is not the same
depending on the model builder believes or not that his unrestricted
model, assuming $-1<\rho_{12}<1$, is correctly specified.  In the
first case, the p-value is computed using the standard chi square
distribution, whereas in the second case a weighted chi square
distribution is used.

<<>>=
vuongtest(model2d, model2i, type = 'nested', hyp = TRUE)
vuongtest(model2d, model2i, type = 'nested', hyp = FALSE)
@

According to these outcomes, the null hypothesis of zero correlation
is accepted or rejected at almost the same significance level, which
must be set higher than 0.066 for acceptance and lower than 0.061 for
rejection.

Testing this hypothesis of no correlation by assuming the unrestricted
model correctly specified, can be also performed by means of the
classical Wald test, using the t-statistic or the p-value of the
correlation coefficient estimate presented in the table of parameter
estimates of the dependent model (\code{model2d}).

<<>>=
coef(summary(model2d), "rho")
@

According to this test outcome, the hypothesis of zero correlation
is accepted at a little less stringent significance level than with
a Vuong test.

Finally, to illustrate the use of the Vuong test for discriminating
between two overlapping models, we consider a slightly different Tobit
model obtained by removing the \code{age} covariate and adding the \code{empl}
and \code{area} covariates :

<<>>=
model3bis <- mhurdle(comics ~ 0 | log(incum) + I(log(incum)^2) +
                     I(log(incum)^3)  + gender + educ + age +
                     empl+area| 0, Comics, dist = "n", method = 'bfgs')
@

In this case, the Vuong test is performed in two steps. Firstly a test
of the null hypothesis $\omega^2=0$, meaning that the two models are
equivalent, is undertaken.

<<>>=
vuongtest(model3, model3bis, type="overlapping")
@

This null hypothesis is here strongly rejected. Therefore, we can
test the equivalence of these two models as if they were strictly non-nested.

<<>>=
vuongtest(model3, model3bis, type="non-nested")
@

According to the outcome of this second test, we conclude that these two
model specifications cannot be empirically discriminated.

If one of two overlapping models is assumed to be correctly specified,
we can bypass the first step of this Voung test (the variance test) and
proceed as if we had to discriminate between two nested models.

<<>>=
vuongtest(model3bis, model3, type="overlapping", hyp=TRUE)
@

Once again, the equivalence of the two models is not rejected.

\section{Conclusion}
\label{sec:conclusion}

\pkg{mhurdle} aims at providing a unified framework allowing to
estimate and assess a variety of extensions of the standard Tobit
model particularly suitable for single-equation demand analysis not
currently implemented in \proglang{R}. It explains the presence of a
large proportion of zero observations for a dependent variable by
means of up to three censoring mechanisms, called hurdles.  Inspired
by the paradigms used for analysing censored household expenditure
data, these hurdles express: (i) a non economic decision mechanism for
a good rejection or selection motivated by ethical, psychological or
social considerations; (ii) an economic decision mechanism for the
desired level of consumption of a previously selected good, which can
turn out to be negative leading to a nil consumption; (iii) an
economic or non economic decision mechanism for the time frequency at
which the desired quantity of a selected good is bought or
consumed. Interdependence between these censoring mechanisms is
modelled by assuming a possible correlation between the random
disturbances in the model relations. Despite the particular area of
application from which the above mentioned censoring mechanisms stem,
the practical scope of \pkg{mhurdle} models doesn't seem to be
restricted to empirical demand analysis.

To provide an operational and efficient statistical framework,
\pkg{mhurdle} models are specified in a fully parametric form allowing
statistical estimation and testing within the maximum likelihood
inferential framework. Tools for model evaluation and selection are
provided, based on the use of goodness of fit measure extensions of
the classical coefficient of determination and of the likelihood ratio
index of McFadden, as well as on the use of Vuong tests for nested,
strictly non-nested and overlapping model comparison when none, one or
both of two competing models are misspecified.

Tests of \pkg{mhurdle} computing procedures with a wide variety of
simulated and observational data have proved the performance and
robustness of \pkg{mhurdle} package. Still, extensions and
improvements of the software are under way, notably the estimation of
trivariate hurdle models in their full generality and the design of a
consistent Vuong testing strategy for discriminating between a
numerous set of competing models. Other desirable extensions, like the
use of less stringent distributional assumptions on which
semi-parametric or nonparametric estimation methods are based, will be
tackled once the actual scope of our models is established through
diversified empirical applications. Research is continuing in this
direction.


\bibliography{bibliomhurdle}

\end{document}
