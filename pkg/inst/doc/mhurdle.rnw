\documentclass[nojss]{jss}
\usepackage{rotating}
\usepackage{amsmath}
\usepackage{wasysym}

\usepackage{amssymb, amsfonts}


%\VignetteIndexEntry{Multiple Hurdle Models in R: the mhurdle Package}
%\VignetteDepends{Formula, truncreg, maxLik}
%\VignetteKeywords{Limited dependent variable, tobit, hurdle models, econometric computing, R}
%\VignettePackage{mhurdle}

\title{Multiple Hurdle Models in \proglang{R}: The \pkg{mhurdle} Package}

\Plaintitle{Multiple Hurdle Models in R: The mhurdle Package}

% \footnote{This package has been developed as part
% of a PhD dissertation carried out by St\'ephane Hoareau
% \cite{Hoareau/09} at the University of La R\'eunion under the
% supervision of Fabrizio Carlevaro and Yves Croissant.}


\author{Fabrizio Carlevaro\\Universit\'e de Gen\`eve \And
 Yves Croissant\\Universit\'e de la R\'eunion \And
 St\'ephane Hoareau\\Universit\'e de la R\'eunion}

\Plainauthor{Fabrizio Carlevaro, Yves Croissant, St\'ephane Hoareau}

\Address{
Fabrizio Carlevaro\\
Facult\'e des sciences \'economiques et sociales\\
Universit\'e de Gen\`eve\\
Uni Mail\\
40 Bd du Pont d'Arve\\
CH-1211 Gen\`eve 4\\
Telephone: +41/22/3798914\\
E-mail:\email{fabrizio.carlevaro@unige.ch}
\\
\\
Yves Croissant\\
Facult\'e de Droit et d'Economie\\
Universit\'e de la R\'eunion\\
15, avenue Ren\'e Cassin\\
BP 7151\\
F-97715 Saint-Denis Messag Cedex 9\\
Telephone: +33/262/938446\\
E-mail: \email{yves.croissant@univ-reunion.fr}
\\
\\
St\'ephane Hoareau\\
Facult\'e de Droit et d'Economie\\
Universit\'e de la R\'eunion\\
15, avenue Ren\'e Cassin\\
BP 7151\\
F-97715 Saint-Denis Messag Cedex 9\\
Telephone: +33/262/938446\\
E-mail: \email{stephane.hoareau@univ-reunion.fr}
}

%% need no \usepackage{Sweave.sty}

\Abstract{ \pkg{mhurdle} is a package for \proglang{R} enabling the
  estimation of a wide set of regression models were the dependent
  variable is left censored at zero, which is typically the case in
  household expenditure surveys.  This kind of models are called
  limited dependent or \emph{Tobit} models in the econometric
  literature and are of particular interest to explain the presence of
  a large proportion of zero observations for the dependent variable
  by means of up to three economic mechanisms, namely: a good
  selection mechanism (hurdle 1), a desired consumption
  mechanism (hurdle 2) and a purchasing mechanism (hurdle 3).
  TO BE COMPLETED}

\Keywords{ limited dependent variable, Tobit models, household
  expenditures models, maximum likelihood estimation, Vuong tests for
  model selection \proglang{R}.}

\Plainkeywords{limited dependent variable, maximum likelihood
  estimation, goodness of fit measures, Vuong tests for model
  selection, R}

\begin{document}

<<echo=FALSE,results=hide>>=
options(prompt= "R> ", useFancyQuotes = FALSE)
@


\maketitle



\section{Introduction}

Data collected by means of households' expenditure survey may present
a large proportion of zero expenditures due to many households
recording, for one reason or another, no expenditure for some
items. Analyzing these data requires to model any expenditure with a
large proportion of nil observations as a dependent variable left
censored at zero.

Since the seminal paper of \citet{TOBIN/58}, a large econometric
literature has been developed to deal correctly with this problem of
zero observations. The problem of censored data has been treated for a
long time in the statistics literature dealing with survival models
which are implemented in \proglang{R} with the \pkg{survival} package
of \citet{SURVA/08}. It has also close links with the problem of
selection bias, for which some methods are implemented in the
\pkg{sampleSelection} package of \citet{TOOME/HENNI/08}. It is also
worth mentioning that a convenient interface to survreg(), called
tobit(), particularly aimed at econometric applications is available
in the AER package of \citet{KLEI/ZEIL/08}.

In applied microeconometrics, different decision mechanisms have been
put forward to explain the appearance of zero expenditure
observations. The original Tobin's model takes only one of these
mechanisms into account. With \pkg{mhurdle}, up to three mechanisms
generating zero expenditure observations may be introduced in the
model\footnote{This package has been developed as part of a PhD
  dissertation carried out by St\'ephane \citet{HOAR/09} at the
  University of La R\'eunion under the supervision of Fabrizio
  Carlevaro and Yves Croissant.}. More specifically, we consider the
following three zero expenditure generating mechanisms.

\begin{description}
\item[A good selection mechanism (hurdle 1)]. According to this
  mechanism, the consumer first decides which goods to include in its
  choice set and, as a consequence, he can discard some marketed goods
  because he dislikes them (like meet for vegetarians or wine for non
  drinker people) or he considers them harmful (like alcohol,
  cigarettes, inorganic food, holidays in dangerous countries), among
  others.

\item[A desired consumption mechanism (hurdle 2)]. According to this
  mechanism, once a good has been selected, the consumer decides at
  which level he desires to consume it and, as a consequence of his
  preferences, resources and selected good prices, its rational
  decision can turn out to be a negative desired consumption level
  leading to a nil consumption.

\item[A purchasing mechanism (hurdle 3)]. According to this mechanism,
  once a consumption decision has been taken, the consumer set up the
  schedule at which to buy the good and, as a consequence of its
  purchasing strategy, zero expenditure may be observed if the survey
  by which these data are collected is carried out over a too short
  period with respect to the frequency at which the good is bought.
\end{description}

For each of these censoring mechanisms, a continuous latent variable
is defined, indicating that censoring is in effect when the latent
variable is negative. These latent variables are modeled as the sum of
a linear combination of explanatory variables and of a normal random
disturbance with a possible correlation between the disturbances of
different latent variables.  By combining part or the whole set of
these censoring mechanisms, we generate a set of non-nested parametric
models that can be used to explain censored expenditure data depending
on the structural censoring mechanisms that a priori information
suggests to be at work. Estimation and inference of these models are
tackled within a maximum likelihood framework and implemented in
\proglang{R} .

\begin{verbatim}
******************************************************************************
ADD SUGGESTIONS:
REVIEW1-C2: about the danger of misspecification and recent
progresses in nonparametric approaches.
REVIEW2-GC4 & EDITOR-M5: About the scope of applications.
******************************************************************************
\end{verbatim}

The paper is organized as follows: Section~\ref{sec:limdepvar}
presents the rationale of our modeling strategy.
Section~\ref{sec:estevalsel} presents the theoretical framework for
model estimation, evaluation and selection. Section~\ref{sec:software}
discusses the software rationale used in the
package. Section~\ref{sec:examples} illustrates the use of
\pkg{mhurdle} with several examples. Section~\ref{sec:conclusion}
concludes.

\section{Modelling strategy}
\label{sec:limdepvar}

\subsection{Model specification}
\label{sec:modelspec}

Our modeling strategy is intended to model the level $y$ of expenditures
of a household for a given good or service during a given period of observation.
To this purpose, we use up to three zero expenditure generating mechanisms,
called hurdles, and a demand function.

Each hurdle is represented by a probit model resting on one of the following three
latent dependent variables relations:

$$
\left\{
\begin{array}{rcl}
  y_1^* = \beta_1^\top x_1 + \epsilon_1 \\
  y_2^* = \beta_2^\top x_2 + \epsilon_2 \\
  y_3^* = \beta_3^\top x_3 + \epsilon_3 \\
\end{array}
\right.
$$

where $x_1$, $x_2$, $x_3$ stand for column-vectors of explanatory
variables (called covariates in the followings), $\beta_1$, $\beta_2$,
$\beta_3$ for column-vectors of the impact coefficients of the
explanatory variables on the continuous latent dependent variables $y_1^*$, $y_2^*$,
$y_3^*$ and $\epsilon_1$, $\epsilon_2$, $\epsilon_3$ for normal random
disturbances.

\begin{itemize}

\item Hurdle 1 models the household decision of selecting or not selecting the good
  we consider as a relevant consumption good. This good selection mechanism
  explains the outcome of a
  binary choice that can be coded by a binary variable $I_1$ taking value 1
  if the household decides to enter the good on its basket of relevant consumption
  goods and 0 otherwise. The outcome of this binary choice is modeled by
  associating the decision to select the good to positive values of latent
  variable $y_1^*$ and that to reject the good to negative values of $y_1^*$.
  Therefore, good selection or rejection is modeled as a probability choice where
  selection occurs with probability $P(I_1=1)=P(y_1^*>0)$ and rejection
  with probability $P(I_1=0)=P(y_1^*\leq 0)=1-P(y_1^*>0)$.\\
  Note that if this mechanism is inoperative, this probit model must be
  replaced by a singular probability choice model where $P(I_1=1)=1$ and
  $P(I_1=0)=0$.

\item Hurdle 2 models the household decision of consuming or not
  consuming the selected good, given its actual economic
  conditions. This desired consumption mechanism explains the outcome
  of a binary choice coded by a binary variable $I_2$ taking value 1
  if the household decides to consume the good and 0 otherwise.  The
  outcome of this binary choice is modeled by associating the decision
  to consume the selected good to a positive value of its desired
  consumption level, represented by latent variable $y_2^*$, and that
  of not to consume the good to negative values of $y_2^*$. Therefore,
  when this zero expenditure generating mechanism is operative, it
  also model the level of desired consumption expenditures by means of
  a Tobit model identifying the desired consumption expenditures to
  the value of latent variable $y_2^*$, when it is positive,and to
  zero, when it is negative.  Conversely, when the desired consumption
  mechanism is inoperative, we must replace, not only the probit model
  explaining variable $I_2$ by a singular probability choice model
  where $P(I_2=1)=1$, but also the Tobit demand function by a demand
  model enforcing non negative values to latent variable $y_2^*$.\ For
  the time being, two functional forms of this demand model have been
  programmed in \pkg{mhurdle}, namely a log-normal functional form :

  $$
  \ln y_2^* = \beta_2^\top x_2+\epsilon_2
  $$

  and a truncated Tobit model, defined by a linear functional form with $\epsilon_2$
  distributed as a normal random disturbance left-truncated at $\epsilon_2 = -\beta_2^\top x_2$,
  as suggested by \citet{CRAGG/71}. Nevertheless, to avoid a cumbersome analytic
  presentation of our models, in the followings we consider only the log-normal
  model specification.

\item Hurdle 3 models the household decision of purchasing or not purchasing
  the good during the survey period over which expenditure data are collected. This
  purchasing mechanism also explains the outcome of a binary choice, coded
  by a binary variable $I_3$ taking value 1 if the household decides
  to buy the good during the period of statistical observation and 0 otherwise.
  The probit model we use associates the purchasing decision to positive
  values of latent variable $y_3^*$ and that of not purchasing to negative
  values of $y_3^*$.\\
  By assuming that consumption and purchases are uniformly distributed over time,
  but according to different timetables entailing a frequency of consumption higher
  than that of purchasing, we can also interpret the probability
  $P(I_3=1)=P(y_3^*>0)$ as measuring the share of expenditures
  to consumption during the observation period. This allows to relate the observed
  level of expenditures $y$ to the unobserved level of consumption $y_2^*$ during
  the observation period, using the following identity:

  $$
  y = \frac{y_2^*}{P(I_3=1)} I_1 I_2 I_3 .
  $$

  When the purchasing mechanism is inoperative, the previous probit model must be
  replaced by a singular probability choice model where $P(I_3=1)=1$.
  In such a case, the observed level of expenditures is identified to the level
  of consumption, implying $y=y_2^* I_1 I_2$.

\end{itemize}

A priori information may suggest that one or more of these censoring
mechanisms are not in effect. For instance, we know in advance that all
households purchase food regularly, implying that the first two
censoring mechanisms are inoperative for food.  In this case, the
relevant model is defined by only two relations: one defining the
desired consumption level of food, according to a log-normal
specification or a truncated Tobit model, and the other the decision of food
purchasing during the observation period.

Figure 1 outlines the full set of special models that can be generated
by selecting which of these three mechanisms are in effect and which are not.
It shows that 8 different models can be dealt with the \pkg{mhurdle}
package.

Among these models, one is not concerned by censored data, namely model 1.
This model is relevant only for modeling uncensored samples. All the
other models are potentially able to analyze censored samples
by combining up to the three censoring mechanisms described
above. With the notable exception of the standard Tobit model 3, that
can be estimated also by the \pkg{survival} package of
\citet{SURVA/08} or the AER package of \citet{KLEI/ZEIL/08}, these models
cannot be found in an other \proglang{R} package.

Some of \pkg{mhurdle} models have already been used in the applied
econometric literature. In particular, model 2 is a single-hurdle
good selection model originated by \citet{CRAGG/71}. The double-hurdle
model combining independent good selection (hurdle 1) and desired consumption
(hurdle 2) censoring mechanisms is also due to \citet{CRAGG/71}. An
extension of this double-hurdle model to dependent censoring mechanisms
has been originated by \citet{BLUNDELL/87}.

P-Tobit model 7 is due to \citet{DEATO/IRISH/84} and explains zero
purchases by combining the desired consumption censoring mechanism
(hurdle 2) with the purchasing censoring mechanism (hurdle 3).
Model 4 is a single-hurdle model not yet used in applied demand analysis,
where the censoring mechanism in effect is that of infrequent purchases
(hurdle 3).

Among the original models encompassed by \pkg{mhurdle}, models 6 is a
double-hurdle model combining good selection (hurdle 1) and purchasing
(hurdle 3) mechanisms to explain censored samples. Model 8 is an
original triple-hurdle model originated in \citet{HOAR/09}.
This model explains censored purchases either as the result of good
rejection (hurdle 1), negative desired consumption (hurdle 2) or
infrequent purchases (hurdle 3).

\begin{figure}[!h]
  \hspace{-1cm} \includegraphics[width=20cm,height=17cm,angle=90]{mhurdle6.pdf}
\caption{\label{arbre2} The full set of mhurdle special models.}
\end{figure}

To derive the form of the probability distribution of the observable
dependent variable $y$, we must specify the joint distribution of the
random disturbances entering into the structural relations of these models.

\begin{itemize}

\item Models 8 and 6 are trivariate hurdle models as they involve disturbances
  $\epsilon_1$, $\epsilon_2$ and $\epsilon_3$, distributed according to the
  trivariate normal density function:
  $$
  \frac{1}{\sigma}\phi\left(\epsilon_1,\frac{\epsilon_2}{\sigma},\epsilon_3;
  \rho_{12},\rho_{13},\rho_{23}\right)
  $$
  where
  $$
  \begin{array}{rcl}
  \phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})&=& \\
  &&\frac{
    \exp\left\{-
      \frac{
        (1-\rho_{23}^2)z_1^2+(1-\rho_{13}^2)z_2^2+(1-\rho_{12}^2)z_3^2
        -2[(\rho_{12}-\rho_{13}\rho_{23})z_1z_2+(\rho_{13}-\rho_{12}\rho_{23})z_1z_3
        +(\rho_{23}-\rho_{12}\rho_{13})z_2z_3]
      }
      {2\mid R\mid}
    \right\}
  }
  {\sqrt{(2\pi)^3}\mid R\mid}
  \end{array}
  $$
  with
  $$
  |R|=1-\rho_{12}^2-\rho_{13}^2-\rho_{23}^2+2\rho_{12}\rho_{13}\rho_{23}
  $$
  denotes the density
  function of a standard trivariate normal distribution and $\rho_{12}$, $\rho_{13}$,
  $\rho_{23}$ the correlation coefficients between the couples of normal standard
  random variables $z_1$ and $z_2$, $z_1$ and $z_3$, $z_2$ and $z_3$, respectively.
  As the unit of measurement of $\epsilon_1$ and $\epsilon_3$ are not identified,
  these disturbances are normalized by setting their variances equal to 1.

\item Models 7 and 4 are bivariate hurdle models as they involve disturbances
  $\epsilon_2$ and $\epsilon_3$, distributed according to the bivariate normal
  density function:
  $$
  \frac{1}{\sigma}\phi\left(\frac{\epsilon_2}{\sigma},\epsilon_3;\rho_{23}\right)
  $$
  where
  $$
  \phi(z_1,z_2;\rho)=\frac{\exp\left\{-\frac{z_1^2+z_2^2-2\rho z_1z_2}{2(1-\rho^2)}\right\}}
  {2\pi\sqrt{1-\rho^2}}
  $$
  denotes the density function of a standard bivariate normal distribution with
  correlation coefficient $\rho$.

\item Models 5 and 2 are also bivariate hurdle models but they involve disturbances
  $\epsilon_1$ and $\epsilon_2$ which density function is therefore written as:
  $$
  \frac{1}{\sigma}\phi\left(\epsilon_1,\frac{\epsilon_2}{\sigma};\rho_{12}\right).
  $$

\item Finally, models 3 and 1 are univariate hurdle models involving only
  disturbance $\epsilon_2$, which density function writes therefore:
  $$
  \frac{1}{\sigma}\phi\left(\frac{\epsilon_2}{\sigma}\right)
  $$
  where
  $$
  \phi(z_1)=\frac{\exp\left\{-\frac{z_1^2}{2}\right\}}{\sqrt{2\pi}}
  $$

  denotes the density function of a standard univariate normal distribution.

\end{itemize}

A priori information may also suggest to set to zero some or all
correlations between the random disturbances entering into these
models, entailing a partial or total independence between the
above defined censoring mechanisms. The use of this a priori
information generates for each trivariate or bivariate hurdle model
of Figure 1 a subset of special models all nested within the
general model from which they are derived. For a trivariate
hurdle model the number of special models so derived is equal
to 7, but for a bivariate hurdle model only one special model is
generated, namely the model obtained by assuming the independence
between the two random disturbances of the model.

In the followings, we shall work out the distribution of our
hurdle models in their general case, but for their implementation
in \proglang{R} only the special cases of independence or dependence
between two censoring mechanisms will be considered. For
trivariate hurdle models this dependence will be restricted to
the pair of hurdles 1 and 2 or hurdles 2 and 3.

\subsection{Likelihood function}

As for the standard Tobit model, the probability distribution of the
observed censored variable $y$ of our hurdle models is a
discrete-continuous mixture, which assign a probability mass $P(y=0)$
to $y=0$ and a density function $f_+(y)$ to any $y>0$, with:

$$
P(y=0)+\int_0^\infty f_+(y)dy=1
$$

The probability mass $P(y=0)=1-P(y>0)$ may be computed by integrating
the joint density function of the latent variables entering into the
hurdle model over their positive values.

\begin{itemize}
\item For trivariate hurdle model 8, using the change of variables:
  $$
  \left\{
  \begin{array}{rcl}
   z_1 & = & y_1^* - \beta_1^\top x_1 \\
   z_2 & = & \frac{y_2^* - \beta_2^\top x_2}{\sigma} \\
   z_3 & = & y_3^* - \beta_3^\top x_3 \\
  \end{array}
  \right.
  $$
  this approach leads to:
  $$
  \begin{array}{rcl}
  P(y=0)&=1-\int_{-\beta_1^\top x_1}^\infty \int_{-\frac{\beta_2^\top x_2}{\sigma}}^\infty
  \int_{-\beta_3^\top x_3}^\infty \phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})
  dz_1 dz_2 dz_3\\
  &=1-\Phi(\beta_1^\top x_1,\frac{\beta_2^\top x_2}{\sigma},
  \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23})
  \end{array}
  $$
  where $\Phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})$ denotes the distribution
  function of a standard trivariate normal distribution with correlation coefficients
  $\rho_{12}$,$\rho_{13}$ and $\rho_{23}$.

\item For trivariate hurdle model 6, using the change of variables:
  $$
  \left\{
  \begin{array}{rcl}
   z_1 & = & y_1^* - \beta_1^\top x_1 \\
   z_2 & = & \frac{\ln y_2^* - \beta_2^\top x_2}{\sigma} \\
   z_3 & = & y_3^* - \beta_3^\top x_3 \\
  \end{array}
  \right.
  $$
  this approach leads to:
  $$
  \begin{array}{rcl}
  P(y=0)&=1-\int_{-\beta_1^\top x_1}^{\infty} \int_{-\infty}^\infty
  \int_{-\beta_3^\top x_3}^{\infty} \phi(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23})
  dz_1 dz_2 dz_3\\
  &=1-\Phi(\beta_1^\top x_1,\beta_3^\top x_3;\rho_{13})
  \end{array}
  $$
  where $\Phi(z_1,z_2;\rho)$ denotes the distribution function of a standard
  bivariate normal distribution with correlation coefficient $\rho$.

\item The probability mass $P(y=0)$ for bivariate hurdle models 7 and 5 and
  univariate hurdle model 3 can be derived from that of trivariate model 8
  by eliminating hurdles 1, 3, 1 and 3, respectively.
  Likewise, this probability for bivariate hurdle models 4 and 2 can be derived
  from that of trivariate hurdle model 6 by eliminating hurdles 1 and 3, respectively.
  Corresponding formulas of $P(y=0)$ for all this special cases implemented in
  \proglang{R} are presented in Table \ref{tab:typo}.
\end{itemize}

\begin{sidewaystable}
  \caption{Typology of the models\label{tab:typo}}\vspace{.5cm}

  \begin{tabular}{|l|lll|lll|l|l|l|}\hline\hline
id & $h_1$ & $h_2$ & $h_3$ & $\rho_{12}$ & $\rho_{13}$ & $\rho_{23}$  & $P(y=0)$ & $f_+(y)$ & $\mbox{E}(y \mid y > 0)$\\\hline\hline
1 &\Square&\Square&\Square&\Square&\Square&\Square& $0$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln y - \beta_2^{\top}x_2}{\sigma}\right)$ & $e^{\beta_2^{\top}x_2 + 0.5\sigma^2}$\\
2i &\CheckedBox&\Square&\Square&\Square&\Square&\Square& $1 - \Phi_1$& $\frac{1}{\sigma y}\phi\left(\frac{\ln y -\beta_2^{\top}x_2}{\sigma}\right)\Phi_1$& $e^{\beta_2^{\top} x_2 + 0.5 \sigma^2}$\\
2d &\CheckedBox&\Square&\Square&\CheckedBox&\Square&\Square & $1 - \Phi_1$& $\frac{1}{\sigma y}\phi\left(\frac{\ln y -\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1+\rho_{12}\frac{\ln y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)$ & $e^{\beta_2^{\top} x_2 + 0.5 \sigma^2(1-\rho_{12}^2)}\frac{\Psi_1}{\Phi_1}$\\
3 &\Square&\CheckedBox&\Square&\Square&\Square&\Square& $1 - \Phi_2$ & $\frac{1}{\sigma}\phi\left(\frac{y-\beta_2^{\top}x_2}{\sigma}\right)$ & $\beta_2^{\top}x_2+\sigma\frac{\phi_2}{\Phi_2}$\\
4i &\Square&\Square&\CheckedBox&\Square&\Square&\Square& $1 - \Phi_3$ & $\frac{\Phi_3}{\sigma y}\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^{\top}x_2}{\sigma}\right)$ & $e^{\beta_2^{\top} x_2 + 0.5 \sigma^2}\frac{1}{\Phi_3}$ \\
4d &\Square&\Square&\CheckedBox&\Square&\Square &\CheckedBox& $1 - \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln (\Phi_3 y)-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\ln (\Phi_3 y) - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)$  & $e^{\beta_2^{\top} x_2 + 0.5 \sigma^2(1-\rho_{23}^2)}\frac{\Psi_1}{\Phi_1}$\\
5i &\CheckedBox&\CheckedBox&\Square&\Square&\Square&\Square& $1 - \Phi_1\Phi_2$ & $\frac{1}{\sigma}\phi\left(\frac{y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_1$ & $\beta_2^{\top} x_2 + \sigma\frac{\phi_2}{\Phi_2}$\\
5d &\CheckedBox&\CheckedBox&\Square&\CheckedBox&\Square&\Square&$1 - \Phi_{12}$ &
$\frac{1}{\sigma}\phi\left(\frac{y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1 + \rho_{12}\frac{y-\beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)$ & $\beta_2^{\top} x_2 + \sigma\frac{\Psi_{21}}{\Phi_{12}}$\\
6i &\CheckedBox&\Square&\CheckedBox&\Square&\Square&\Square& $1 - \Phi_1 \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln (\Phi_3 y) -\beta_2^{\top}x_2}{\sigma}\right)\Phi_1\Phi_3$ &$e^{\beta_2^{\top}x_2+0.5 \sigma^2}$ \\
6d1 &\CheckedBox&\Square&\CheckedBox&\CheckedBox&\Square&\Square& $1 - \Phi_1 \Phi_3$ &  $\frac{1}{\sigma y}\phi\left(\frac{(\ln \Phi_3 y) -\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1+\rho_{12}\frac{(\ln y \Phi_3) - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)\Phi_3$& $e^{\beta_2^{\top} x_2 + 0.5 \sigma^2(1-\rho_{12}^2)}\frac{\Psi_1}{\Phi_1}$\\
6d3 &\CheckedBox&\Square&\CheckedBox&\Square&\Square &\CheckedBox& $1 - \Phi_1 \Phi_3$ & $\frac{1}{\sigma y}\phi\left(\frac{\ln (\Phi_3 y)-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\ln (\Phi_3 y) - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)\Phi_1$& $e^{\beta_2^{\top} x_2 + 0.5 \sigma^2(1-\rho_{23}^2)}\frac{\Psi_3}{\Phi_3}$\\
7i &\Square&\CheckedBox&\CheckedBox&\Square&\Square&\Square& $1 - \Phi_2 \Phi_3$& $\frac{1}{\sigma}\phi\left(\frac{\Phi_3y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_3^2$& $\frac{\beta_2^{\top} x_2}{\Phi_3} +\frac{\sigma}{\Phi_3}\frac{\phi_2}{\Phi_2}$\\
7d &\Square&\CheckedBox&\CheckedBox&\Square&\Square &\CheckedBox& $1 - \Phi_{23}$& $\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\Phi_3 y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)$& $\frac{\beta_2^{\top} x_2}{\Phi_3} + \frac{\sigma}{\Phi_3}\frac{\Psi_{23}}{\Phi_{23}}$ \\
8i  &\CheckedBox&\CheckedBox&\CheckedBox&\Square&\Square&\Square& $1-\Phi_1\Phi_2\Phi_3$& $\frac{\Phi_3^2}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi_1$& $\frac{\beta_2^{\top} x_2}{\Phi_3} + \frac{\sigma}{\Phi_1}\frac{\phi_2}{\Phi_2}$ \\
8d1 &\CheckedBox&\CheckedBox&\CheckedBox&\CheckedBox&\Square&\Square&$1 - \Phi_{12}\Phi_3$& $\frac{\Phi_3^2}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_1^{\top}x_1 + \rho_{12}\frac{\Phi_3 y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{12}^2}}\right)$& $\frac{\beta_2^{\top} x_2}{\Phi_3} + \frac{\sigma}{\Phi_3}\frac{\Psi_{21}}{\Phi_{12}}$ \\
8d3 &\CheckedBox&\CheckedBox&\CheckedBox&\Square&\Square &\CheckedBox&$1 - \Phi_1\Phi_{23}$& $\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^{\top}x_2}{\sigma}\right)\Phi\left(\frac{\beta_3^{\top}x_3 + \rho_{23}\frac{\Phi_3 y - \beta_2^{\top}x_2}{\sigma}}{\sqrt{1-\rho_{23}^2}}\right)\Phi_1$& $\frac{\beta_2^{\top} x_2}{\Phi_3} + \frac{\sigma}{\Phi_3}\frac{\Psi_{23}}{\Phi_{23}}$  \\ \hline\hline
\end{tabular}

\end{sidewaystable}

The density function $f_+(y)$ may be computed by performing: first the change of
variables

$$
y_2^* = P(I_3=1)y = \Phi(\beta_3^\top x_3)y=\Phi_3y
$$

on the joint density function of the latent variables entering into the
hurdle model; than by integrating this transformed density function over
the positive values of latent variables $y_1^*$ and $y_3^*$.

\begin{itemize}
\item For trivariate hurdle model 8 this transformed density function
  is written as:
  $$
  \frac{\Phi_3}{\sigma}\phi\left(y_1^*-\beta_1^\top x_1,\frac{\Phi_3 y-\beta_2^\top x_2}
  {\sigma},y_3^*-\beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)
  $$
  To perform the analytical integration of this function, it is useful
  to rewrite it as the product of the marginal distribution of $y$, namely:
  $$
  \frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)
  $$
  and of the joint density function of $y_1^*$ and $y_3^*$ conditioned
  with respect to $y$, which can be written as follows:
  $$
  \frac{1}{\sigma_{1|2}\sigma_{3|2}}\phi\left(\frac{y_1^*-\mu_{1|2}}{\sigma_{1|2}},
  \frac{y_3^*-\mu_{3|2}}{\sigma_{3|2}}; \rho_{13|2}\right)
  $$
  with:
  $$
  \mu_{1|2}=\beta_1^\top x_1+\rho_{12}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma}, \quad
  \mu_{3|2}=\beta_3^\top x_3+\rho_{23}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma},
  $$
  $$
  \sigma_{1|2}^2=1-\rho_{12}^2, \quad \sigma_{3|2}^2=1-\rho_{23}^2,
  \quad
  \rho_{13|2}=\frac{\rho_{13}-\rho_{12}\rho_{23}}{\sqrt{1-\rho_{12}^2}\sqrt{1-\rho_{23}^2}}.
  $$

  Using this factorization of the density function of $y_1^*$, $y$ and $y_3^*$,
  we obtain:
  $$
  \begin{array}{rcl}
    f_+(y)&=\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)
    \int_0^\infty\int_0^\infty \frac{1}{\sigma_{1|2}\sigma_{3|2}}\phi\left(\frac{y_1^*-\mu_{1|2}}{\sigma_{1|2}},
      \frac{y_3^*-\mu_{3|2}}{\sigma_{3|2}}; \rho_{13|2}\right)dy_1^*dy_3^* \\
    &=\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)
    \int_{-\frac{\mu_{1|2}}{\sigma_{1|2}}}^\infty\int_{-\frac{\mu_{3|2}}{\sigma_{3|2}}}^\infty
    \phi(z_1,z_3;\rho_{13|2})dz_1 dz_3 \\
    &=\frac{\Phi_3}{\sigma}\phi\left(\frac{\Phi_3 y-\beta_2^\top x_2}{\sigma}\right)
    \Phi\left(\frac{\beta_1^\top x_1+\rho_{12}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma}}
      {\sqrt{1-\rho_{12}^2}},\frac{\beta_3^\top x_3+\rho_{23}\frac{\Phi_3y-\beta_2^\top x_2}{\sigma}}
      {\sqrt{1-\rho_{23}^2}};\frac{\rho_{13}-\rho_{12}\rho_{23}}{\sqrt{1-\rho_{12}^2}\sqrt{1-\rho_{23}^2}}\right). \\
      \end{array}
      $$

\item For trivariate hurdle model 6, we proceed as for hurdle model 8 by
  substituting the joint normal density function of $y_1^*$, $y$ and $y_2^*$,
  by the following joint normal/log-normal density function:

  $$
  \frac{1}{\sigma y}\phi\left(y_1^*-\beta_1^\top x_1,\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}
  {\sigma},y_3^*-\beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right).
  $$

  To integrate this density function with respect to the positive values of
  $y_1^*$ and $y_2^*$, we rewrite it as the product of the marginal distribution
  of $y$, which is log-normal:

  $$
  \frac{1}{\sigma y}\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}\right)
  $$

  and of the joint density function of $y_1^|y*$ and $y_3^*|y$, which is bivariate normal:

  $$
  \frac{1}{\sigma_{1|2}\sigma_{3|2}}\phi\left(\frac{y_1^*-\mu_{1|2}}{\sigma_{1|2}},
  \frac{y_3^*-\mu_{3|2}}{\sigma_{3|2}}; \rho_{13|2}\right)
  $$
  with:
  $$
  \mu_{1|2}=\beta_1^\top x_1+\rho_{12}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}, \quad
  \mu_{3|2}=\beta_3^\top x_3+\rho_{23}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma},
  $$
  $$
  \sigma_{1|2}^2=1-\rho_{12}^2, \quad \sigma_{3|2}^2=1-\rho_{23}^2, \quad
  \rho_{13|2}=\frac{\rho_{13}-\rho_{12}\rho_{23}}{\sqrt{1-\rho_{12}^2}\sqrt{1-\rho_{23}^2}}.
  $$

  By integrating this factorization of the density function of $y_1^*$, $y$ and $y_3^*$,
  over the positive values of $y_1^*$ and $y_3^*$, we obtain:

  $$
  \begin{array}{rcl}
    f_+(y)&=&\frac{1}{\sigma y}\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}\right)
    \int_{-\frac{\mu_{1|2}}{\sigma_{1|2}}}^\infty\int_{-\frac{\mu_{3|2}}{\sigma_{3|2}}}^\infty
    \phi(z_1,z_3;\rho_{13|2})dz_1 dz_3 \\
    &=&\frac{1}{\sigma y}\phi\left(\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}\right)
    \Phi\left(\frac{\beta_1^\top x_1+\rho_{12}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}}
    {\sqrt{1-\rho_{12}^2}},\frac{\beta_3^\top x_3+\rho_{23}\frac{\ln(\Phi_3 y)-\beta_2^\top x_2}{\sigma}}
    {\sqrt{1-\rho_{23}^2}};\frac{\rho_{13}-\rho_{12}\rho_{23}}{\sqrt{1-\rho_{12}^2}\sqrt{1-\rho_{23}^2}}\right) \\
    \end{array}
    $$

\item The density function $f_+(y)$ for bivariate hurdle models 7 and 5 and
  univariate hurdle model 3 can be derived from that of trivariate model 8
  by eliminating hurdles 1, 3, 1 and 3, respectively.
  Likewise, this density function for bivariate hurdle models 4 and 2 can be derived
  from that of trivariate hurdle model 6 by eliminating hurdles 1 and 3, respectively.
  Corresponding formulas of $f_+(y)$ for all this special cases implemented in
  \proglang{R} are presented in Table~\ref{tab:typo}.
\end{itemize}

From these results it is easy to derive the likelihood function of a
random sample of $n$ observations of the censored dependent variable $y$.
As these observations are all independently drawn from the same conditional
(with respect to covariates $x_1$, $x_2$ and $x_3$) discrete-continuous distribution,
which assign a conditional probability mass $P(y=0)$ to the observed value $y=0$ and
a conditional density function $f_+(y)$ to the observed values $y>0$,
the log-likelihood function for an observation $y_i$ can be written as :
$$
\ln L_i = \left\{
  \begin{array}{lll}
    \ln P(y_i=0) & \mbox{if} & \quad y_i=0 \\
    \ln f_+(y_i) & \mbox{if} & \quad y_i>0 \\
\end{array}
\right.
$$

and the log-likelihood for the entire random sample:

$$
\ln L = \sum_{i=1}^n \ln L_i= \sum_{i \mid y_i = 0} \ln P(y_i=0) + \sum_{i \mid y_i > 0} \ln f_+(y_i).
$$



\section{Model estimation, evaluation and selection}
\label{sec:estevalsel}

The econometric framework described in the previous section provides a
theoretical framework for tackling the problems of model estimation,
evaluation and selection within the statistical theory of classical
inference.

\subsection{Model estimation}

The full parametric specification of our multiple hurdle models allows
to efficiently estimate their parameters by means of the maximum
likelihood principle. Indeed, it is well known from classical
estimation theory that, under the assumption of correct model
specification and for a likelihood function sufficiently well behaved,
the maximum likelihood estimator is asymptotically efficient within
the class of consistent and asymptotically normal
estimators\footnote{See \citet{AMEM/85} chapter 4, for a more rigorous
statement of this property.}.


More precisely, the asymptotic distribution of the maximum likelihood
estimator $\hat{\theta}$ for the parameter vector $\theta$ of a
multiple hurdle model, is written as:

$$
\hat{\theta} \overset{A}{\sim} N(\theta,\frac{1}{n} I_A (\theta)^{-1})
$$

where $\overset{A}{\sim}$ stands for "asymptotically distributed as" and

$$
I_A(\theta)=\mbox{plim} \frac{1}{n} \sum_{i=1}^n E\left(\frac{\partial^2
  \ln L_i (\theta)}{\partial \theta \partial \theta^\top}\right)
=\mbox{plim} \frac{1}{n} \sum_{i=1}^n E\left(\frac{\partial\ln
  L_i(\theta)}{\partial\theta} \frac{\partial\ln L_i
  (\theta)}{\partial\theta^\top}\right)
$$

for the asymptotic Fisher information matrix of a sample of $n$
independent observations.

More generally, any inference about a differentiable vector function
of $\theta$, denoted by $\gamma=h(\theta)$, can be based on the
asymptotic distribution of its implied maximum likelihood estimator
$\hat{\gamma}=h(\hat{\theta})$.  This distribution can be derived from
the asymptotic distribution of $\hat{\theta}$ according to the so
called delta method:

$$
\hat{\gamma} \overset{A}{\sim} h(\theta)+\frac{\partial
  h}{\partial\theta^\top} (\hat\theta-\theta) \overset{A}{\sim}
N\left(\gamma,\frac{1}{n} \frac{\partial h}{\partial\theta^\top}I_A
(\theta)^{-1}\frac{\partial h^\top}{\partial\theta}\right)
$$

The practical use of these asymptotic distributions requires to
replace the theoretical variance-covariance matrix of these asymptotic
distributions with consistent estimators, which can be obtained by
using $\frac{\partial h (\hat{\theta})}{\partial\theta^\top}$ as a
consistent estimator for $\frac{\partial h
  (\theta)}{\partial\theta^\top}$ and either $\frac{1}{n} \sum_{i=1}^n
\frac{\partial^2\ln L_i
  (\hat{\theta})}{\partial\theta\partial\theta^\top}$ or $\frac{1}{n}
\sum_{i=1}^n \frac{\partial\ln L_i(\hat{\theta})}{\partial\theta}
\frac{\partial\ln L_i (\hat{\theta})}{\partial\theta^\top}$ as a
consistent estimator for $I_A(\theta)$. The last two estimators are
directly provided by two standard iterative methods used to compute
the maximum likelihood parameter's estimate, namely the Newton-Raphson
method and the Berndt, Hall, Hall, Hausman or \textsc{bhhh} method,
respectively, mentioned in section 4.3.

\subsection{Model evaluation}

Two fundamental principles should be used to appraise the results of a
model estimation, namely its economic relevance and its statistical
and predictive adequacy. The first principle deals with the issues of
accordance of model estimate with the economic rationale underlying
the model specification and of its relevance for answering the
questions for which the model has been built. These issues are
essentially context specific and, therefore, cannot be dealt with
generic criteria.  The second principle refers to the issues of
empirical soundness of model estimate and of its ability to predict
sample or out-of-sample observations.  These issues can be tackled by
means of formal tests of significance, based on the previously
presented asymptotic distributions of model estimates, and by measures
of goodness of fit/prediction, respectively.

To assess the goodness of fit of \pkg{mhurdle} estimates, two pseudo $R^2$
coefficients are provided. The first one is an extension of the
classical coefficient of determination, used to explain the fraction
of variation of the dependent variable explained by the covariates
included in a linear regression model with intercept. The second one
is an extension of the likelihood ratio index introduced
\citet{MCFA/74} to measure the relative gain in the maximized
log-likelihood function due to the covariates included in a
qualitative response model.

To define a pseudo coefficient of determination, we rely on the non
linear regression model explaining the dependent variable of a multiple hurdle
model. This model is written as:

$$
y=E(y)+u
$$

where $u$ stands for a zero expectation, heteroskedastic random disturbance and
$E(y)$ for the expectation of the censored dependent variable $y$:

$$
E(y)=0 \times P(y=0)+\int_0^\infty yf_+(y)dy=\int_0^\infty yf_+(y)dy.
$$

To compute this expectation, we reformulate it as a multiple integral of the
joint density function of $y_1^*$, $y$ and $y_3^*$ multiplied by $y$, over
the positive values of these variables.

\begin{itemize}
\item For trivariate hurdle model 8, using the change of variables:
  $$
  \left\{
  \begin{array}{rcl}
   z_1 & = & y_1^* - \beta_1^\top x_1 \\
   z_2 & = &\frac{\Phi_3 y - \beta_2^\top x_2}{\sigma} \\
   z_3 &= &y_3^* - \beta_3^\top x_3 \\
  \end{array}
  \right.
  $$
  this reformulation of $E(y)$ is written as:
  $$
  \begin{array}{rcl}
    E(y)&=&\int_{-\beta_1^\top x_1}^\infty \int_{\frac{-\beta_2^\top x_2}{\sigma}}^\infty
    \int_{-\beta_3^\top x_3}^\infty \frac{\beta_2^\top x_2+\sigma z_2}{\Phi_3}
    \phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right) dz_1 dz_2 dz_3 \\
    &=&\frac{\beta_2^\top x_2}{\Phi_3}\Phi\left(\beta_1^\top x_1,\frac{-\beta_2^\top x_2}{\sigma},
      \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)\\
    &+&\frac{\sigma}{\Phi_3}
    \int_{-\beta_1^\top x_1}^\infty \int_{\frac{-\beta_2^\top x_2}{\sigma}}^\infty
    \int_{-\beta_3^\top x_3}^\infty z_2\phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right) dz_1 dz_2 dz_3
  \end{array}
  $$
  To perform the analytical integration of the second term of the right-hand side
  of this formula, it is useful to rewrite the density function of $z_1$, $z_2$
  and $z_3$ as the product of the marginal density function of $z_1$ and $z_2$, namely:
  $$
  \phi\left(z_1,z_2;\rho_{13}\right)
  $$
  and of the density function of $z_2$ conditioned with respect to $z_1$ and $z_3$,
  which can be written as follows:
  $$
  \frac{1}{\sigma_{2|1,3}}\phi\left(\frac{z_2-\mu_{2|1,3}}{\sigma_{2|1,3}}\right)
  $$
  where:
  $$
  \mu_{2|1,3}=\varrho_1 z_1 + \varrho_3 z_3, \quad
  \sigma_{2|1,3}=\frac{1-\rho_{12}^2-\rho_{13}^2-\rho_{23}^2+2\rho_{12}\rho_{13}\rho_{23}}
  {1-\rho_{13}^2}.
  $$
  with:
  $$
  \varrho_1=\frac{\rho_{12}-\rho_{13}\rho_{23}}{1-\rho_{13}^2}, \quad
  \varrho_3=\frac{\rho_{23}-\rho_{12}\rho_{13}}{1-\rho_{13}^2}.
  $$

  Using this factorization of the density function of $z_1$, $z_2$ and $z_3$,
  we get:
  $$
  \begin{array}{l}
    \int_{-\beta_1^\top x_1}^\infty \int_{\frac{-\beta_2^\top x_2}{\sigma}}^\infty
    \int_{-\beta_3^\top x_3}^\infty z_2\phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right)
    dz_1 dz_2 dz_3\\
    \int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty
    \left(\int_{\frac{-\beta_2^\top x_2}{\sigma}}^\infty z_2\phi\left(\frac{z_2-\mu_{2|1,3}}
        {\sigma_{2|1,3}}\right)\frac{dz_2}{\sigma_{2|1,3}}\right)\phi\left(z_1,z_2;\rho_{13}\right)dz_1 dz_3
  \end{array}
  $$

  By performing the change of variable:
  $$
  z=\frac{z_2 - \mu_{2|1,3}}{\sigma_{2|1,3}}
  $$
  the integral with respect to $z_2$ simplifies to:
  $$
  \int_{\frac{-\beta_2^\top x_2}{\sigma}}^\infty z_2\phi\left(\frac{z_2-\mu_{2|1,3}}
  {\sigma_{2|1,3}}\right)=
  \mu_{2|1,3}\Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\mu_{2|1,3}}{\sigma_{2|1,3}}\right)
  +\sigma_{2|1,3}\phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\mu_{2|1,3}}{\sigma_{2|1,3}}\right)
  $$

  By inserting this result in the above formulas we finally obtain:
  $$
  E(y)=\frac{\beta_2^\top x_2}{\Phi_3}\Phi\left(\beta_1^\top x_1,\frac{-\beta_2^\top x_2}{\sigma},
  \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)+\frac{\sigma}{\Phi_3}
  \Psi\left(\beta_1^\top x_1,\frac{-\beta_2^\top x_2}{\sigma},
  \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)
  $$
  with:
  $$
  \begin{array}{l}
  \Psi\left(\beta_1^\top x_1,\frac{-\beta_2^\top x_2}{\sigma},
  \beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)= \\
  \int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty
  \left[
    \left(\varrho_1 z_1+\varrho_3 z_3 \right)
    \Phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}
        +\varrho_1 z_1+\varrho_3 z_3}{\sigma_{2|1,3}}+\sigma_{2|1,3}\right)
    \phi\left(\frac{\frac{\beta_2^\top x_2}{\sigma}+\varrho_1 z_1+\varrho_3 z_3}{\sigma_{2|1,3}}\right)
  \right]\phi\left(z_1,z_3;\rho_{13}\right) dz_1 dz_3
  \end{array}
  $$

\item For trivariate hurdle model 6, we proceed as for hurdle model 8 by first
  substituting the joint normal density function of $y_1^*$, $y$ and $y_3^*$,
  by the joint normal/log-normal density function introduced in section 2.2,
  than by performing the change of variables:
  $$
  \left\{
  \begin{array}{rcl}
   z_1 = y_1^* - \beta_1^\top x_1 \\
   z_2 =\frac{\ln\left(\Phi_3 y\right) - \beta_2^\top x_2}{\sigma} \\
   z_3 = y_3^* - \beta_3^\top x_3 \\
  \end{array}
  \right.
  $$
  This leads to the following expression of the expected value of $y$:
  $$
\begin{array}{rcl}
  E(y)&=&\int_{-\beta_1^\top x_1}^\infty \int_{-\infty}^\infty
  \int_{-\beta_3^\top x_3}^\infty \frac{\exp\{\beta_2^\top x_2+\sigma z_2\}}{\Phi_3}
  \phi\left(z_1,z_2,z_3;\rho_{12},\rho_{13},\rho_{23}\right) dz_1 dz_2 dz_3 \\
  &=&\frac{\exp\{\beta_2^\top x_2\}}{\Phi_3}\int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty
  \left[\int_{-\infty}^\infty \exp(\sigma z_2)\phi\left(\frac{z_2-\mu_{2|1,3}}
  {\sigma_{2|1,3}}\right)\frac{dz_2}{\sigma_{2|1,3}}\right]\phi\left(z_1,z_3;\rho_{13}\right)dz_1 dz_3
\end{array}
  $$
  obtained by factorizing the density function of $z_1$, $z_2$ and
  $z_3$ as the product of the marginal density function of $z_1$ and
  $z_3$
  times the density function of $z_2|z_1,z_3$.\\
  By performing the change of variable:
  $$
  z=\frac{z_2 - \mu_{2|1,3}}{\sigma_{2|1,3}}
  $$
  the integral with respect to $z_2$ simplifies to:
  $$
  \begin{array}{rcl}
    \int_{-\infty}^\infty \exp\{\sigma z_2\}\phi\left(\frac{z_2-\mu_{2|1,3}}
      {\sigma_{2|1,3}}\frac{dz_2}{\sigma_{2|1,3}}\right)&=&\int_{-\infty}^\infty
    \exp\{\sigma (\mu_{2|1,3}+\sigma_{2|1,3}z)\}\phi(z)dz \\
    &=&\exp\left\{\sigma\mu_{2|1,3}+\frac{\sigma^2\sigma_{2|1,3}^2}{2}\right\}
    \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty
    \exp\left\{-\frac{(z-\sigma\sigma_{2|1,3})^2}{2}\right\}dz \\
    &=&\exp\left\{\sigma\mu_{2|1,3}+\frac{\sigma^2\sigma_{2|1,3}^2}{2}\right\}
  \end{array}
  $$
  By inserting this result in the above formulas we finally obtain:
  $$
  E(y)=\frac{\exp\left\{\beta_2^\top x_2+\frac{\sigma^2\sigma_{2|1,3}^2}{2}\right\}}
  {\Phi_3}\psi(\beta_1^\top x_1,\beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23})
  $$
  with:
  $$
  \psi\left(\beta_1^\top x_1,\beta_3^\top x_3;\rho_{12},\rho_{13},\rho_{23}\right)=
  \int_{-\beta_1^\top x_1}^\infty \int_{-\beta_3^\top x_3}^\infty
  \exp\{\sigma\left(\varrho_1 z_1+\varrho_3 z_3 \right)\}\phi\left(z_1,z_3;\rho_{13}\right)dz_1dz_3.
  $$

\item The expectation of $y$ for bivariate hurdle models 7 and 5 and
  univariate hurdle model 3 can be derived from that of trivariate
  model 8 by eliminating hurdles 1, 3, 1 and 3, respectively.
  Likewise, the expectation of $y$ for bivariate hurdle models 4 and 2
  can be derived from that of trivariate hurdle model 6 by eliminating
  hurdles 1 and 3, respectively.  Corresponding formulas of $E(y|y>0)=
  E(y)/P(y>0)$ for all this special cases implemented in \proglang{R}
  are presented in Table~\ref{tab:typo}.
\end{itemize}

Denoting by $\hat{y}_i$ the fitted values of $y_i$ obtained by
estimating the mean square error predictor $E(y_i)$ for $y_i$ with the
maximum likelihood estimate of model parameters, we define a pseudo
coefficient of determination for a multiple hurdle model using the
following formula:

$$
R^2=1-\frac{RSS}{TSS}
$$

with $RSS=\sum (y_i - \hat{y}_i)^2$ the residual sum of squares and
$TSS=\sum (y_i - \hat{y}_0)^2$ the total sum of squares, where
$\hat{y}_0$ denotes the maximum likelihood estimate of $E(y_i)$ in the
multiple hurdle model without covariates (intercept-only model). Notice that
this goodness of fit measure cannot exceed one but can be negative, as
a consequence of the non linearity of $E(y_i)$ with respect to the
parameters.

Two other formulas, which are equivalent to compute $R^2$ in the
linear regression model with intercept, could have been used to define
a pseudo coefficient of determination, namely: the ratio of the
explained sum of square to the total sum of squares or the squared
correlation between actual and fitted values. We disregarded these
alternatives because the former measure can exceed one in a non linear
regression model, while the latter, although providing values always
within zero and one, cannot be adjusted for degrees of freedom for a
use as a model selection criterion. A more promising approach consists
in computing $RSS$ and $TSS$ with standardized residuals, to correct
for the heteroskedasticity of raw residuals. This standardized pseudo
coefficient of determination is written as:

$$
R_S^2=1-\frac{SRSS}{STSS}
$$

with $SRSS=\sum (y_i - \hat{y}_i)^2/\hat{\sigma}_i^2$ the standardized
residual sum of squares and $STSS=\sum
(y_i-\hat{y}_0)^2/\hat{\sigma}_0^2$ the standardized total sum of
squares, where $\hat{\sigma}_i^2$ denotes the maximum likelihood
estimate of $V(y_i)$ in the multiple hurdle model with covariates and
$\hat{\sigma}_0^2$ that in the corresponding multiple hurdle model
without covariates (intercept-only model). This Pearson goodness of
fit measure, that requires to write down analytically $V(y_i)$, will
be implemented in a next version of \pkg{mhurdle}.

The extension of the McFadden likelihood ratio index for qualitative
response models to multiple hurdle models is straightforwardly obtained by
substituting in this index formula:

$$
\rho^2=1-\frac{\ln L(\hat{\theta})}{\ln L(\hat{\alpha})}=\frac{\ln
  L(\hat{\alpha})-\ln L(\hat{\theta})}{\ln L(\hat{\alpha})}
$$

the maximized log-likelihood function of a qualitative response model
with covariates and the log-likelihood function of the corresponding
model without covariates or intercept-only model, with the maximized
log-likelihood functions of a multiple hurdle model with covariates, $\ln
L(\hat{\theta})$, and without covariates, $\ln L(\hat{\alpha})$,
respectively.  This goodness of fit measure takes values within zero
and one and, as it can be easily inferred from the above second
expression of $\rho^2$, it measures the relative increase of the
maximized log-likelihood function due to the use of explanatory
variables with respect to the maximized log-likelihood function of a
naive intercept-only model.

\subsection{Model selection}

Model selection deals with the problem of discriminating between
alternative model specifications used to explain the same dependent
variable, with the view of finding the one best suited to explain the
sample of observations at hand.  This decision problem can be tackled
from two point of view, namely that of the model specification
achieving the best in-sample fit, on one hand, and that of the model
specification that is favored in a formal test comparing two model
alternatives, on the other hand.



The first selection criterion is easy to apply as it consists in
comparing one of the above defined measures of fit, computed for the
competing model specifications, after adjusting them for the loss of
sample degrees of freedom due to model parametrization.  Indeed, the
value of these measures of fit can be improved by increasing model
parametrization, in particular when the parameter estimates are
obtained by optimizing a criteria functionally related to the selected
measure of fit, as it is the case when using the $\rho^2$ fit measure
with a maximum likelihood estimate. Consequently, a penalty that
increases with the number of model parameters should be added to the
$R^2$ and $\rho^2$ fit measures to trade off goodness of fit
improvements with parameter parsimony losses.



To define an adjusted pseudo coefficient of determination, we rely on
\citet{THEIL/73}'s correction of $R^2$ in a linear regression model,
defined by

$$
\bar{R}^2=1-\frac{n-K_0}{n-K}\frac{RSS}{TSS}
$$

where $K$ and $K_0$ stand for the number of parameters of the multiple
hurdle model with covariates and without covariates,
respectively. Therefore, choosing the model specification with the
largest $\bar{R}^2$ is equivalent to choosing the model specification
with the smallest model residual variance estimate:
$s^2=\frac{RSS}{n-K}$.

To define an adjusted likelihood ratio index, we replace in this
goodness of fit measure $\rho^2$ the log-likelihood criterion with the
Akaike information criterion $AIC=-2\ln
L(\hat{\theta})+2K$. Therefore, choosing the model specification with
the largest

$$
\bar{\rho}^2=1-\frac{\ln L(\hat{\theta})-K}{\ln L(\hat{\alpha})-K_0}
$$

is equivalent to choosing the model specification that minimizes the
\citet{AKAIKE/73} predictor of the Kullback-Leibler Information
Criterion (KLIC). This criterion measures the distance between the
conditional density function $f(y|x;\theta)$ of a possibly
misspecified parametric model and that of the true unknown model,
denoted by $h(y|x)$. It is defined by the following formula:

$$
KLIC=E\left[\ln
  \left(\frac{h(y|x)}{f(y|x;\theta_\ast)}\right)\right]=\int \ln
\left(\frac{h(y|x)}{f(y|x;\theta_\ast)}\right)dH(y,x)
$$

where $H(y,x)$ denotes the distribution function of the true joint
distribution of $(y,x)$ and $\theta_\ast$ the probability limit, with
respect to $H(y,x)$, of $\hat{\theta}$ the so called quasi-maximum
likelihood estimator obtained by applying the maximum likelihood when
$f(y|x;\theta)$ is misspecified.

Our second model selection criterion relies on the use of a test
proposed by \citet{VUONG/89}. According to the rationale of this test,
the "best" parametric model specification among a collection of
competing specifications is the one that minimizes the $KLIC$
criterion or, equivalently, the specification for which the quantity:

$$
E[\ln f(y|x;\theta_\ast)]=\int \ln f(y|x;\theta_\ast)dH(y,x)
$$

is the largest. Therefore, given two competing conditional models with
density functions $f(y|x;\theta)$ and $g(y|x;\pi)$ and parameter
vectors $\theta$ and $\pi$ of size $K$ and $L$, respectively, Vuong
suggests to discriminate between these models by testing the null
hypothesis:

$$
H_0 : E[\ln f(y|x;\theta_\ast)]=E[\ln g(y|x;\pi_\ast)]
\Longleftrightarrow E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]=0
$$

meaning that the two models are equivalent, against:

$$
H_f : E[\ln f(y|x;\theta_\ast)]>E[\ln g(y|x;\pi_\ast)]
\Longleftrightarrow
E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]>0
$$

meaning that specification $f(y|x;\theta)$ is better than
$g(y|x;\pi)$, or against:

$$
H_g : E[\ln f(y|x;\theta_\ast)]<E[\ln g(y|x;\pi_\ast)]
\Longleftrightarrow
E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]<0
$$

meaning that specification $g(y|x;\pi)$ is better than $f(y|x;\theta)$.

The quantity $E[\ln f(y|x;\theta_\ast)]$ is unknown but it can be
consistently estimated, under some regularity conditions, by $1/n$
times the log-likelihood evaluated at the quasi-maximum likelihood
estimator. Hence $1/n$ times the log-likelihood ratio (LR) statistic

$$
LR(\hat{\theta},\hat{\pi})=\sum_{i=1}^n
\ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}
$$

is a consistent estimator of
$E\left[\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right]$. Therefore,
an obvious test of $H_0$ consists in verifying whether the LR
statistic differs from zero.  The distribution of this statistic can
be work out even when the true model is unknown, as the quasi-maximum
likelihood estimators $\hat{\theta}$ and $\hat{\pi}$ converge in
probability to the pseudo-true values $\theta_\ast$ and $\pi_\ast$,
respectively, and have asymptotic normal distributions centered on
these pseudo-true values.

The resulting distribution of $LR(\hat{\theta},\hat{\pi})$ depends on
the relation linking the two competing models. To this purpose, Vuong
differentiates among three types of competing models, namely: nested,
strictly non nested and overlapping.

A parametric model $G_\pi$ defined by the conditional density function
$g(y|x;\pi)$ is said to be nested in parametric model $F_\theta$ with
conditional density function $f(y|x;\theta)$, if and only if any
conditional density function of $G_\pi$ is equal to a conditional
density function of $F_\theta$ almost everywhere (disregarding any
zero probability sub-set of $(y,x)$ values, with respect to the true
distribution function $H(y,x)$). This means that we can write a
parametric constraint in the form $\theta=T(\pi)$, allowing to express
model $G_\pi$ as a particular case of model $F_\theta$. Within our
multiple hurdle special models this is the case when comparing two
specifications differing only with respect to the presence or the
absence of correlated disturbances.  For these models, it is
necessarily the case that $f(y|x;\theta_\ast)\equiv
g(y|x;\pi_\ast)$. Therefore $H_0$ is tested against $H_f$.

If model $F_\theta$ is misspecified, it has been shown by Kent(1982) that:

\begin{itemize}
\item under $H_0$, the quantity $2LR(\hat{\theta},\hat{\pi})$
  converges in distribution towards a weighted sum of $K$ iid
  $\chi^2(1)$ random variables, where the weights are the $K$
  almost surely real and non negative eigenvalues of the following
  $K \times K$ matrix:

  $$
  \underline{W}=B_f\left[DA_g^{-1}D^\top -A_f^{-1}\right]
  $$

  where

  $$
  A_f=E\left(\frac{\partial^2\ln
      f(y|x;\theta_\ast)}{\partial\theta\partial\theta^\top}\right),\quad
  A_g=E\left(\frac{\partial^2\ln
      g(y|x;\pi_\ast)}{\partial\pi\partial\pi^\top}\right),
  $$
  $$
  B_f=E\left(\frac{\partial\ln
      f(y|x;\theta_\ast)}{\partial\theta}\frac{\partial\ln
      f(y|x;\theta_\ast)}{\partial\theta^\top}\right),\quad
  D=\frac{\partial T(\pi_\ast)}{\partial\pi^\top}.
  $$

\item under $H_f$, the same statistic converge almost surely towards
  $+\infty$.

\end{itemize}

Performing this robustified version of the standard LR test for nested models,
requires to replace the theoretical matrix $\underline{W}$ by a consistent
estimator. Such an estimator is obtained by substituting matrices $A_f$, $A_g$,
$B_f$ for their sample analogue:

$$
\hat{A}_f=\frac{1}{n}\sum_{i=1}^n\frac{\partial^2\ln
  f(y_i|x_i;\hat{\theta})}{\partial\theta\partial\theta^\top},\quad
\hat{A}_g=\frac{1}{n}\sum_{i=1}^n\frac{\partial^2\ln
  g(y_i|x_i;\hat{\pi})}{\partial\pi\partial\pi^\top},
$$
$$
\hat{B}_f=\frac{1}{n}\sum_{i=1}^n\frac{\partial\ln
  f(y_i|x_i;\hat{\theta})}{\partial\theta}\frac{\partial\ln f(y_i|x_i;
  \hat{\theta})}{\partial\theta^\top}
$$

and $D$ for $\hat{D}=\partial T(\hat{\pi})/\partial\pi^\top$.

The density function of this asymptotic test statistic has not
been worked out analytically. Therefore, we compute it by simulation.

Hence, for a test with critical value $c$, $H_0$ is rejected in favor
of $H_f$ if $2LR(\hat{\theta},\hat{\pi})>c$ or if the p-value
associated to the observed value of $2LR(\hat{\theta},\hat{\pi})$ is
less than the significance level of the test.

Notice that, if model $F_\theta$ is correctly specified, the
asymptotic distribution of the LR statistic is, as expected, a
$\chi^2$ random variable with $K-L$ degrees of freedom.

Two parametric models $F_\theta$ and $G_\pi$ defined by conditional
distribution functions $f(y|x;\theta)$ and $g(y|x;\pi)$ are said to be
strictly non-nested, if and only if no conditional distribution
function of model $F_\theta$ is equal to a conditional distribution
function of $G_\pi$ almost everywhere, and conversely. Within multiple
hurdle special models this is the case when comparing two
specifications differing with respect either to the censoring
mechanisms in effect or to the functional form of the desired
consumption equation. For these models, it is necessarily the case
that $f(y|x;\theta_\ast)\neq g(y|x;\pi_\ast)$ implying that both
models are misspecified under $H_0$.

For such strictly non-nested models, Vuong has shown that:

\begin{itemize}
\item under $H_0$, the quantity $n^{-1/2}LR(\hat{\theta},\hat{\pi})$
  converges in distribution towards a normal random variable with zero
  expectation and variance:
 $$
 \omega^2=V\left(\ln\frac{f(y|x;\theta_\ast)}{g(y|x;\pi_\ast)}\right)
 $$
 computed with respect to the distribution function of the true joint
 distribution of $(y,x)$.
\item under $H_f$, the same statistic converge almost surely towards
  $+\infty$.
\item under $H_g$, the same statistic converge almost surely towards
  $-\infty$.
\end{itemize}

Hence, $H_0$ is tested against $H_f$ or $H_g$ using the standardized
LR statistic:

$$
T_{LR}=\frac{LR(\hat{\theta},\hat{\pi})}{\sqrt{n}\hat{\omega}}
$$

where $\hat{\omega}^2$ denotes the following strongly consistent
estimator for $\omega^2$:

$$
\hat{\omega}^2=\frac{1}{n}\sum_{i=1}^n
\left(\ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}\right)^2
-\left(\frac{1}{n}\sum_{i=1}^n
  \ln\frac{f(y_i|x_i;\hat{\theta})}{g(y_i|x_i;\hat{\pi})}\right)^2 .
$$

As a consequence, for a test with critical value $c$, $H_0$ is
rejected in favor of $H_f$ if $T_{LR}>c$ or if the p-value associated
to the observed value of $T_{LR}$ in less than the significance level
of the test. Conversely, $H_0$ is rejected in favor of $H_g$ if
$T_{LR}<-c$ or if the p-value associated to the observed value of
$|T_{LR}|$ in less than the significance level of the test.

Notice that, if one of models $F_\theta$ or $G_\pi$ is assumed to be
correctly specified, the \citet{COX/61,COX/62} LR test of non nested
models needs to be used. Because this test is computationally awkward
to implement and not really one of model selection, as it can lead to
reject both competing models, it has not been programmed in \pkg{mhurdle}.

Two parametric models $F_\theta$ and $G_\pi$ defined by conditional
distribution functions $f(y|x;\theta)$ and $g(y|x;\pi)$ are said to be
overlapping, if and only if part of the conditional distribution
function of model $F_\theta$ is equal to the conditional distribution
function of $G_\pi$ but none of these models is nested in the
other. Within multiple hurdle special models this is the case when
comparing two specifications differing only with respect to the
covariates taken into consideration, some of them being common to
both models and others specific. For these models it is not clear
\emph{a priori} as to whether or not $f(y|x;\theta_\ast)=
g(y|x;\pi_\ast)$ almost everywhere, except if we know \emph{a priori}
that at least one of the two competing models is correctly
specified. As a consequence, the form of the asymptotic distribution
of $LR(\hat{\theta},\hat{\pi})$ under $H_0$ is unknown, which prevents
from performing a model selection test based on this statistic.

In the general case where both competing models are wrongly specified,
Vuong suggest a sequential procedure which consists in testing first
whether or not the variance $\omega^{2}$ equals zero (since
$f(y|x;\theta_\ast)= g(y|x;\pi_\ast)$ almost everywhere if and only if
$\omega^{2}=0$) and then, according to the outcome of this test, in
using the appropriate asymptotic $LR(\hat{\theta},\hat{\pi})$
distribution to perform the model selection test.

To test $H_0^{\omega}: \omega^2=0$ against $H_A^{\omega}: \omega^2\neq
0$, Vuong suggests to use, as a test statistic, the above defined
strongly consistent estimator for $\omega^2$, $\hat{\omega}^2$, and
proves that:

\begin{itemize}
\item under $H_0^{\omega}$, the quantity $n\hat{\omega}^2$ converges
  in distribution towards a weighted sum of $K+L$ iid $\chi^2(1)$
  random variables, where the weights are the $K+L$ almost surely real
  and non negative eigenvalues of the following $(K+L) \times (K+L)$
  matrix:

  $$
  W=\left[ \begin{array}{c}
  -B_f A_f^{-1}\quad \  \quad -B_{fg} A_g^{-1} \\
  -B_{fg}^\top A_f^{-1} \ \quad -B_g A_g^{-1}
  \end{array} \right]
  $$

  where $A_f$, $A_g$ and $B_f$ are defined as in matrix
  $\underline{W}$ whereas

  $$
  B_g=E\left(\frac{\partial\ln
      g(y|x;\pi_\ast)}{\partial\pi}\frac{\partial\ln
      g(y|x;\pi_\ast)}{\partial\pi^\top}\right),\quad
  B_{fg}=E\left(\frac{\partial\ln
      f(y|x;\theta_\ast)}{\partial\theta}\frac{\partial\ln
      g(y|x;\pi_\ast)}{\partial\pi^\top}\right).
  $$

\item under $H_A^{\omega}$, the same statistic converge almost surely
  towards $+\infty$.
\end{itemize}

Performing this variance test, requires to replace the theoretical
matrix $W$ by a consistent estimator obtained by substituting matrices
$A_f$, $A_g$, $B_f$, $B_g$ and $B_{fg}$ for their sample analogue. The
density function of this asymptotic test statistic has not been worked
out analytically.  Therefore, we compute it by simulation.

Hence, for a test with critical value $c$, $H_0^\omega$ is rejected in
favor of $H_A^\omega$ if $n\hat{\omega}^2>c$ or if the p-value
associated to the observed value of $n\hat{\omega}^2$ is less than the
significance level of the test.

The second step in discriminating two overlapping models depends on
the outcome of the variance test.

\begin{itemize}
\item If $H_0^\omega$ is not rejected, one should conclude that the
  two models cannot be discriminated given the data, since assuming
  $\omega^2=0$ implies $H_0$ meaning that the two models are
  equivalent.
\item If $H_0^\omega$ is rejected, the test of $H_0$ against $H_f$ or
  $H_g$ must be carried out using the standardized LR statistic
  $T_{LR}$, as for discriminating between two strictly non nested
  models. Indeed, $H_0$ is still possible when $\omega^2\neq0$. Note,
  that this sequential procedure of testing $H_0$ against $H_f$ or
  $H_g$ has a significance level bounded above by the maximum of the
  significance levels used for performing the variance and the
  standardized LR tests.
\end{itemize}

Finally, if one of the two competing models is supposed to be
correctly specified, then the two models are equivalents if and only
if the other model is correctly specified and if and only the
conditional density functions of the two models are identical almost
everywhere. In this case we can bypass the variance test and directly
construct a model selection test based on the
$2LR(\hat{\theta},\hat{\pi})$ test statistic as for discriminating
between two nested models.


\section{Software rationale}
\label{sec:software}

There are three important issues to be addressed to correctly
implement in \proglang{R} the econometric framework described in the
previous section. The first one is to provide a good interface to
describe the model to be estimated. The second one is the problem of
finding good starting values for computing model estimates. The third
one is to offer flexible optimization tools for likelihood
maximization.

\subsection{Model syntax}
\label{sec:modeldesc}


In \proglang{R}, the model to be estimated is usually described using
formula objects, the left-hand side denoting the censored dependent
variable \texttt{y} and the right-hand side the functional relation
explaining \texttt{y} as a function of covariates. For example,
\texttt{y \~{} x1 + x2*x3} indicates that \texttt{y} linearly depends
on variables \texttt{x1}, \texttt{x2}, \texttt{x3} and on the
interaction term \texttt{x2} times \texttt{x3}.

For the models implemented in \pkg{mhurdle}, three kinds of covariates
should be specified: the ones of the selection equation (denoted
$x_1$), the ones of the consumption equation (denoted $x_2$), and
those of the infrequency equation (denoted $x_3$). To define a model
with three kinds of covariates, a general solution is given by the
\pkg{Formula} package developed by \citet{ZEIL/CROI/10}, which
provides extended formula objects. To define a model where \texttt{y}
is the censored dependent variable, \texttt{x21} and \texttt{x22} two
covariates for the desired consumption equation, \texttt{x11} and
\texttt{x12} two covariates for the selection and \texttt{x31} and
\texttt{x32} two covariates for the infrequency of purchase equation,
we use the following commands :

<<>>=
library("Formula")
f <- Formula(y ~ x11 + x12  | x21 + x22 | x31 + x32)
@


\subsection{Starting values}
\label{sec:startvalues}

For the models we consider, the log-likelihood function will be, in
general, not concave. Moreover, this kind of models are highly non
linear with respect to parameters, and therefore difficult to
estimate. For these reasons, the question of finding good starting
values for the iterative computation of parameter estimates is
crucial.

As a less computer intensive alternative to maximum likelihood
estimation, \citet{HECKM/76} has suggested a two step estimation
procedure based on a respecification of the censored variable linear
regression model, sometimes called ``Heckit'' model, avoiding
inconsistency of ordinary least-squares estimator.  This two step
estimator is consistent but inefficient. It is implemented in package
\pkg{sampleSelection} \citep{TOOME/HENNI/08}.

According to \citet{CARL/CROI/HOAR/08} experience in applying this
estimation procedure to two-hurdle models, this approach doesn't seem
to work well with our correlated hurdle-models. Indeed, except for the
very special case of model 3 (log-normal correlated single-hurdle
selection model), the probability of observing a censored purchase is
not that of a simple probit model (see the formula of $\ln L_i^-$).

As noted previously, for uncorrelated single-hurdle good selection
models, the estimation may be performed in a sequence of two simple
estimations, namely the maximum likelihood estimation of a standard
dichotomous probit model, followed by the ordinary least-squares
estimation of a linear, log-linear or linear-truncated regression
model. In the last case, package \pkg{truncreg} \citep{TRUNCR/09} is
used.

In case of correlated single-hurdle good selection models, the
coefficient maximum likelihood estimate of the corresponding
uncorrelated model ($\rho=0$) is used as starting values.

For purchase infrequency models (P-Tobit models), the starting values
are computed using an Heckman-like two step procedure. In the first
step, parameters $\beta_3$ are estimated using a simple probit. In the
second step, a linear, log-linear or linear-truncated model is
estimated on the sub-sample of uncensored observations using
$y_i\Phi(\beta_3^{'}x_3)$ or $\ln y_i +\ln \Phi(\beta_3^{'}x_3)$ (in
the case of a log-normal specification) as the dependent variable of
the regression model estimated by ordinary least squares.

\subsection{Optimisation}
\label{sec:optimisation}

Two kinds of routines are currently used for maximum likelihood
estimation. The first one can be called ``Newton-like'' methods. With
these routines, at each iteration, an estimation of the log-likelihood
hessian matrix is computed, using either the second derivatives of the
criterion function (Newton-Raphson method) or the outer product of the
gradient (Berndt, Hall, Hall, Hausman or \textsc{bhhh} method). This approach
is very powerful if the criterion function is well-behaved, but it may
perform poorly otherwise and fail after a few iterations.

The second one, called Broyden, Fletcher, Goldfarb, Shanno or
\textsc{bfgs} method, updates at each iteration an estimate of the
log-likelihood hessian matrix. It is often more robust and may perform
better in cases where the former doesn't work.

Two optimization functions are included in core \proglang{R}:
\code{nlm}, which uses the Newton-Raphson method, and \code{optim} ,
which uses the \textsc{bfgs} method (among others). The recently developed
\pkg{maxLik} package by \citet{MAXLIK/08} provides a unified
framework. With a unique interface, all the previously described
methods are available.

The behavior of \code{maxLik} can be controlled by the user using
\code{mhurdle} arguments like \texttt{print.level} (from 0-silent to
2-verbal), \texttt{iterlim} (the maximum number of iterations),
\texttt{methods} (the method used, one of \texttt{"nr"},
\texttt{"bhhh"} or \texttt{"bfgs"}) that are passed to \code{maxLik}.

\section{Examples}
\label{sec:examples}

The package is loaded using:

<<>>=
library("mhurdle")
@

To illustrate the use of \pkg{mhurdle}, we use the \code{Comics} data
frame which contains data about the readings of comics. It is part of
a survey conducted by the \textsc{insee} (the French public
statistical institute) in 2003 about cultural and sportive
practices. The explained variable is the number of comics read during
the last 12 months by one (randomly chosen) member of the
household. There are 5159 observations.

<<>>=
data("Comics", package = "mhurdle")
head(Comics, 3)
mean(Comics$comics == 0)
max(Comics$comics)
@

The number of Comics read is zero for about 78\% of the sample and the
maximum value is 520.

The covariates of this data frame are :

\begin{description}
\item[area:] one of \code{rural}, \code{small}, \code{medium},
  \code{large} and \code{paris},
\item[income:] the income of the household (in thousands of euros per
  month),
\item[uc:] the number of consumption unit (one for the first two
  adults, one half for other members of the household),
\item[size :] the number of persons in the household,
\item[age : ] the age of the person,
\item[empl : ] the kind of job, a factor with 9 levels,
\item[gender: ] one of \code{male} and \code{female},
\item[couple,] does the person live in couple ? a factor with levels
  \code{yes} and \code{no},
\item[educ : ] the number of years of education.
\end{description}


\subsection{Estimation}

The estimation is performed using the \code{mhurdle} function, which
has the following arguments:

\begin{description}
\item[formula:] a formula describing the model to estimate. It should
  have three parts on the right-hand side specifying, in the first
  part, the good selection equation covariates, in the second
  part, the desired consumption equation covariates and, in the third part,
  the purchase frequency equation covariates.
\item[data:] a data frame containing the observations of the variables
  present in the formula.
\item[subset, weights, na.action:] these are arguments passed on to
  the model.frame function in order to extract the data suitable for
  the model. These arguments are present in the \code{lm} function and
  most of the estimation functions.
\item[start:] the starting values. If \code{NULL}, the starting values
  are computed as described in the previous section.
\item[dist:] this argument indicates the functional form of the
  desired consumption equation, which may be: either log-normal
  \code{"l"} (the default), normal \code{"n"} or truncated normal
  \code{"t"}.
\item[corr:] a logical argument indicating whether the disturbances of
  the selection equation or of the purchase mechanism equation is
  correlated with the one of the consumption. This argument is in this
  case respectively equal to \code{"h1"} or \code{"h3"}, or
  \code{NULL} (the default) in case of no correlation,
\item[...] further arguments that are passed to the optimization
  function \code{maxLik}.
\end{description}

Different combinations of these arguments lead to a large variety of
models. Note that some of them are logically inconsistent and
therefore irrelevant. For example, a model with no good selection
equation and \code{corr = "h1"} is logically inconsistent.

To illustrate the use of \pkg{mhurdle} package, we first estimate a
simple tobit model, which we call \code{model3} ; the income is
divided by the number of consumption units and divided by its sample
mean. Powers up to three for the log of income are introduced.

<<>>=
Comics$incuc <- with(Comics, income / uc)
Comics$incucm <- with(Comics, incuc / mean(incuc))
model3 <- mhurdle(comics ~ 0 | log(incucm) + I(log(incucm)^2) + I(log(incucm)^3)
                             + age  + gender + educ + empl | 0,
                  Comics, dist = "n", method = 'bfgs')
@

Note that the first and the third part of the formula consist are 0,
as there is no selection and no purchase mechanism equations.

Consider now that some covariates explains the fact that the good is
selected, and not the level of consumption if the good is chosen. In
this case, we estimate the following dependent two-hurdle model, which
we call \code{model5d}. We keep the income and the size of the
household as covariates for the consumption equation and move the
other covariates on the first part of the formula.

<<>>=
model5d <- mhurdle(comics ~ gender + age + educ + empl |
                   log(incucm) + I(log(incucm)^2) + I(log(incucm)^3) | 0,
                   Comics, corr = "h1", dist = "n", method = 'bfgs')
@

The same model without correlation is called \code{model5i}, and can
easily be obtained by updating \code{model5d}.

<<>>=
model5i <- update(model5d, corr = NULL)
@

If one wants that the only source of 0 arise from the selection
process, one has to switch the \code{dist} argument to \code{"l"}, so
that a log-normal distribution is introduced. This can be done easily
by updating the previous model and this leads to a model called
\code{model2d}

<<>>=
model2d <- update(model5d, dist = "l")
@

The next model we estimate is a single hurdle dependent P-tobit model
which we call \code{model4d} ; \code{size} is the covariate used in
the purchase equation :

<<>>=

model4d <- mhurdle(comics ~ 0 | log(incucm) + I(log(incucm)^2) + I(log(incucm)^3)
                             + age  + gender + educ + empl | size,
                  Comics, dist = "n", method = 'bfgs')
@

The last model we estimate is a dependent three-hurdle model, with
\code{size} used for the purchasing equation. This model, called
\code{model8d1} is estimated by updating \code{model5d} and adding
\code{size} in the third part of the formula. As it is a very
parametrized and difficult to estimate model, we also provide starting
values, using the coefficients of \code{model5d} and adding 3 and 0
for the coefficients of the intercept and of \code{size} in the
purchase equation.

<<>>=
model8d1 <- update(model5d, . ~ . | . | . + size + 1, start = c(coef(model5d)[1:16], 2, 0, coef(model5d)[17:18]))
@

\subsection{Methods}

A \code{summary} method is provided for \code{mhurdle} objects :

<<>>=
summary(model8d1)
@

This method displays the percentage of 0 in the sample, the
coefficient table, and several measures of goodness of fit.

\code{coef}, \code{vcov}, \code{logLik}, \code{predict} methods are
provided in order to extract part of the results.

Coefficients and the estimated asymptotic variance matrix of maximum
likelihood estimators are extracted using the usual \code{coef} and
\code{vcov} functions. \code{mhurdle} object methods have a second
argument indicating which subset has to be returned (the default is to
return all).

<<>>=
coef(model8d1, "h2")
coef(model5d, "h1")
coef(model5d, "sigma")
coef(summary(model8d1), "h2")
vcov(model5d, "h2")
@

Log-likelihood may be obtained for the estimated model or for a
``naive'' model, \emph{i.e.} a model without covariates :

<<>>=
logLik(model5d)
logLik(model5d, naive = TRUE)
@

Fitted values are obtained using the \code{fitted} method.  The
output is a matrix whose two columns are the estimated probability of
censoring $Prob \{ y_i=0 \}$ and the estimated expected value of an
uncensored dependent variable observation $E(y_i | y_i>0)$.

<<>>=
head(fitted(model5d))
@

A \code{predict} function is also provided, which returns the same
two columns for given values of the covariates.

<<>>=
pr <- predict(model5d,
              newdata = data.frame(
                comics = c(0, 1, 2),
                gender = c("female", "female", "male"),
                age = c(20, 18, 32),
                educ = c(10, 20, 5),
                empl = c("employed", "worker", "manag"),
                incucm = c(4, 8, 2),
                size = c(2, 1, 3)))
head(pr)
@


For model evaluation and selection purposes, goodness of fit measures
and Vuong tests described in section 3 are provided. These criteria
allow to select the most empirically appropriate model specification.

Two goodness of fit measures are provided. The first measure is an
extension to limited dependent variable models of the classical
coefficient of determination for linear regression models. This pseudo
coefficient of determination is computed both without ($R^2$) and with
($\bar{R}^2$) adjustment for the loss of sample degrees of freedom due
to model parametrization.  The unadjusted coefficient of determination
allows to compare the goodness of fit of model specifications having
the same number of parameters, whereas the adjusted version of this
coefficient is suited for comparing model specifications with a
different number of parameters.

<<>>=
r.squared(model5d, type = "regression")
@

The second measure is an extension to limited dependent variable
models of the likelihood ratio index for qualitative response
models. This pseudo coefficient of determination is also computed both
without ($\rho^2$) and with ($\bar{\rho}^2$) adjustment for the loss
of sample degrees of freedom due to model parametrization, in order to
allow model comparisons with the same or with a different number of
parameters.

<<>>=
r.squared(model5d, type = "mcfadden", dfcor = TRUE)
@

The Vuong test based on the $T_{LR}$ statistic, as presented in
section 3.3, is also provided as a criteria for model selection within
the family of 12 strictly non nested models of FIG. 1.

<<>>=
vuongtest(model5d, model8d1)
@

% In the previous example, the Vuong test also suggest that the double
% hurdle dependent model is the best suited model within the family of
% trihurdle models.

Testing the hypothesis of no correlation between the good selection
mechanism and the desired consumption equation can be performed by
means of a Wald test, a Lagrange multiplier (LM) test or a
log-likelihood ratio (LR) statistic.


Likelihood ratio tests are performed using a Vuong test, and more
precisely the nested version of this test. As explained in section
3.3, the critical value or the p-value to be used to perform this test
is not the same depending on the model builder believes or not that
his model is correctly specified. In the first case, the p-value is
computed using the standard chi square distribution, in the second
case a weighted chis square distribution is used.


<<>>=
vuongtest(model5d, model5i, type = 'nested', hyp = TRUE)
vuongtest(model5d, model5i, type = 'nested', hyp = FALSE)
@


The LM test is performed using the independent model
(\code{model8i}). The \code{summary} method performs the test, as seen
previously, the p-value for this test is 0.494.  The Wald test is
simply obtained in the coefficient table of the dependent model
(\code{model8d})

<<>>=
coef(summary(model5d), "rho")
@

In the previous example, all the tests reject the hypothesis of no
correlation.

\section{Conclusion}
\label{sec:conclusion}

\pkg{mhurdle} aims at providing a unified framework allowing to
estimate and assess a variety of extensions of the standard
\emph{Tobit} model particularly suitable for single-equation demand
analysis not currently implemented in \proglang{R} .

\bibliography{bibliomhurdle}

\end{document}


